{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import numpy as np\n",
    "\n",
    "import codecs\n",
    "import argparse\n",
    "import csv\n",
    "import random\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# very useful feature used to reload python modules\n",
    "from importlib import reload\n",
    "\n",
    "# import module that loads data, tokenises the tuples, initialises the embeddings matrix\n",
    "import crim_data\n",
    "\n",
    "import multiprojection_model\n",
    "# contains code to evaluate according to semeval2018 metrics\n",
    "import semeval_eval\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise embeddings and normalise to unit-norm\n",
    "model = KeyedVectors.load_word2vec_format('embeddings/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "#model = KeyedVectors.load_word2vec_format('embeddings/glove.42B.300d.txt', binary=False)\n",
    "#model = KeyedVectors.load_word2vec_format('embeddings/wiki-news-300d-1M.vec', binary=False)\n",
    "\n",
    "#model.save_word2vec_format('embeddings/GoogleNews-vectors-negative300.txt', binary=False)\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tuples in entire set: 7397\n",
      "Unique hyponyms in set: 2259\n"
     ]
    }
   ],
   "source": [
    "# import Ustalov et al. prepare module\n",
    "import prepare\n",
    "\n",
    "sub_train = prepare.read_subsumptions('subsumptions-train.txt')\n",
    "sub_test = prepare.read_subsumptions('subsumptions-test.txt')\n",
    "sub_validation = prepare.read_subsumptions('subsumptions-validation.txt')\n",
    "synonyms = prepare.read_synonyms('synonyms.txt')  \n",
    "\n",
    "# remove vocab term having no vector in embeddings\n",
    "def get_terms_having_vectors(w2v, dataset):\n",
    "    return [(q,h) for q, h in dataset if q in w2v and h in w2v]\n",
    "\n",
    "sub_train = get_terms_having_vectors(model, sub_train)\n",
    "sub_test = get_terms_having_vectors(model, sub_test)\n",
    "sub_validation = get_terms_having_vectors(model, sub_validation)\n",
    "synonyms = prepare.get_synonymys_having_vectors(synonyms, model)\n",
    "synonyms.default_factory = None\n",
    "\n",
    "# create hypernym dictionary\n",
    "hyper_dict = defaultdict(list)\n",
    "for x, y in sub_train + sub_test + sub_validation:        \n",
    "    hyper_dict[x].append(y)\n",
    "    \n",
    "hyper_dict.default_factory = None\n",
    "\n",
    "print (\"Total number of tuples in entire set: %d\" % (len([x for (x,y) in sub_train + sub_test + sub_validation])))\n",
    "print (\"Unique hyponyms in set: %d\" % (len(set([x for (x,y) in sub_train + sub_test + sub_validation]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.batch_size        = args['batch_size']\n",
    "        self.phi_k             = args['phi_k']\n",
    "        self.lambda_c          = args['lambda_c']\n",
    "        self.epochs            = args['epochs']        \n",
    "        self.negative_sample_n = args['negative_sample_n']\n",
    "        self.synonym_sample_n  = args['synonym_sample_n']\n",
    "        \n",
    "        # this object generates the predictions from a model's learned parameters\n",
    "        self.evaluator = args['evaluator']\n",
    "        # this object scores the predictions according to MRR, MAP, P@k (k in {1,5,10,15})\n",
    "        self.scorer = args['scorer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'w2v':model,\n",
    "        'train':sub_train, 'test':sub_test, 'validation':sub_validation, 'synonyms':synonyms, \n",
    "        'limited_vocab_n': 250000,\n",
    "        # model parameters        \n",
    "        'batch_size': 32, 'phi_k': 1, 'lambda_c': 1., 'epochs': 10, \n",
    "        'negative_sample_n': 10, 'synonym_sample_n': 5\n",
    "       }\n",
    "#data = crim_data.CrimData(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['data'] = data\n",
    "args['evaluator'] = None\n",
    "args['scorer'] = None\n",
    "\n",
    "model = multiprojection_model.MultiProjModel(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': [], 'loss': [], 'test_loss': []}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch Pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'multiprojection_model' from '/home/jovyan/work/hyperstar/multiprojection_model.py'>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reload(crim_data)\n",
    "reload(multiprojection_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
