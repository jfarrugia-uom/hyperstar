{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from projlearn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_string( 'model',  'baseline', 'Model name.')\n",
    "flags.DEFINE_string( 'train', 'train.npz', 'Training set.')\n",
    "flags.DEFINE_string( 'test',   'test.npz', 'Test set.')\n",
    "flags.DEFINE_float(  'stddev',        .01, 'Value of stddev for matrix initialization.')\n",
    "flags.DEFINE_float(  'lambdac',       .10, 'Value of lambda.')\n",
    "flags.DEFINE_integer('seed',          1337, 'Random seed.')\n",
    "flags.DEFINE_integer('num_epochs',    700, 'Number of training epochs.')\n",
    "flags.DEFINE_integer('batch_size',   1024, 'Batch size.')\n",
    "flags.DEFINE_boolean('gpu',          False, 'Try using GPU.')\n",
    "\"\"\"\n",
    "# Parameters\n",
    "model_type = 'regularized_synonym_phi'\n",
    "#model_type = 'baseline'\n",
    "train_vectors = 'train.npz'\n",
    "test_vectors = 'test.npz'\n",
    "stddev = 0.1\n",
    "lambdac = 0.1\n",
    "#lambdac = 0\n",
    "#seed = 1337\n",
    "seed = 1000\n",
    "num_epochs = 700\n",
    "batch_size = 1024\n",
    "gpu = False\n",
    "\n",
    "w2v = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, callback=lambda: None):\n",
    "    train_op = tf.train.AdamOptimizer(epsilon=1.).minimize(model.loss)\n",
    "\n",
    "    train_losses, test_losses = [], []\n",
    "    train_times = []\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        sess.run(init_op)\n",
    "\n",
    "        feed_dict_train, feed_dict_test = {\n",
    "            model.X: data.X_train,\n",
    "            model.Y: data.Y_train,\n",
    "            model.Z: data.Z_train\n",
    "        }, {\n",
    "            model.X: data.X_test,\n",
    "            model.Y: data.Y_test,\n",
    "            model.Z: data.Z_test\n",
    "        }\n",
    "\n",
    "        steps = max(data.Y_train.shape[0] // batch_size, 1)\n",
    "\n",
    "        print('Cluster %d: %d train items and %d test items available; using %d steps of %d items.' % (\n",
    "            data.cluster + 1,\n",
    "            data.X_train.shape[0],\n",
    "            data.X_test.shape[0],\n",
    "            steps,\n",
    "            min(batch_size, data.X_train.shape[0])),\n",
    "        flush=True)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            X, Y, Z = data.train_shuffle()\n",
    "\n",
    "            for step in range(steps):\n",
    "                head =  step      * batch_size\n",
    "                tail = (step + 1) * batch_size\n",
    "\n",
    "                feed_dict = {\n",
    "                    model.X: X[head:tail, :],\n",
    "                    model.Y: Y[head:tail, :],\n",
    "                    model.Z: Z[head:tail, :]\n",
    "                }\n",
    "\n",
    "                t_this = datetime.datetime.now()\n",
    "                sess.run(train_op, feed_dict=feed_dict)\n",
    "                t_last = datetime.datetime.now()\n",
    "\n",
    "                train_times.append(t_last - t_this)\n",
    "\n",
    "            if (epoch + 1) % 10 == 0 or (epoch == 0):\n",
    "                train_losses.append(sess.run(model.loss, feed_dict=feed_dict_train))\n",
    "                test_losses.append(sess.run(model.loss,  feed_dict=feed_dict_test))\n",
    "\n",
    "                print('Cluster %d: epoch = %05d, train loss = %f, test loss = %f.' % (\n",
    "                    data.cluster + 1,\n",
    "                    epoch + 1,\n",
    "                    train_losses[-1] / data.X_train.shape[0],\n",
    "                    test_losses[-1]  / data.X_test.shape[0]),\n",
    "                file=sys.stderr, flush=True)\n",
    "\n",
    "        t_delta = sum(train_times, datetime.timedelta())\n",
    "        print('Cluster %d done in %s.' % (data.cluster + 1, str(t_delta)), flush=True)\n",
    "        callback(sess)\n",
    "\n",
    "        return sess.run(model.Y_hat, feed_dict=feed_dict_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "if not gpu:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "with np.load(train_vectors) as npz:\n",
    "    X_index_train = npz['X_index']\n",
    "    Y_all_train   = npz['Y_all']\n",
    "    Z_all_train   = npz['Z_all']\n",
    "\n",
    "with np.load(test_vectors) as npz:\n",
    "    X_index_test  = npz['X_index']\n",
    "    Y_all_test    = npz['Y_all']\n",
    "    Z_all_test    = npz['Z_all']\n",
    "\n",
    "X_all_train = Z_all_train[X_index_train[:, 0], :]\n",
    "X_all_test  = Z_all_test[X_index_test[:, 0],   :]\n",
    "\n",
    "kmeans = pickle.load(open('kmeans.pickle', 'rb'))\n",
    "\n",
    "clusters_train = kmeans.predict(Y_all_train - X_all_train)\n",
    "clusters_test  = kmeans.predict(Y_all_test  - X_all_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RegularizedSynonymPhi lambda=0.100000>\n",
      "./regularized_synonym_phi.k1.trained\n",
      "Cluster 1: 72 train items and 12 test items available; using 1 steps of 72 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cluster 1: epoch = 00001, train loss = 1.914667, test loss = 1.879742.\n",
      "Cluster 1: epoch = 00010, train loss = 1.888259, test loss = 1.854691.\n",
      "Cluster 1: epoch = 00020, train loss = 1.842801, test loss = 1.811686.\n",
      "Cluster 1: epoch = 00030, train loss = 1.788292, test loss = 1.760276.\n",
      "Cluster 1: epoch = 00040, train loss = 1.728872, test loss = 1.704432.\n",
      "Cluster 1: epoch = 00050, train loss = 1.667302, test loss = 1.646803.\n",
      "Cluster 1: epoch = 00060, train loss = 1.605547, test loss = 1.589269.\n",
      "Cluster 1: epoch = 00070, train loss = 1.545025, test loss = 1.533183.\n",
      "Cluster 1: epoch = 00080, train loss = 1.486731, test loss = 1.479491.\n",
      "Cluster 1: epoch = 00090, train loss = 1.431339, test loss = 1.428822.\n",
      "Cluster 1: epoch = 00100, train loss = 1.379262, test loss = 1.381560.\n",
      "Cluster 1: epoch = 00110, train loss = 1.330715, test loss = 1.337893.\n",
      "Cluster 1: epoch = 00120, train loss = 1.285763, test loss = 1.297864.\n",
      "Cluster 1: epoch = 00130, train loss = 1.244363, test loss = 1.261413.\n",
      "Cluster 1: epoch = 00140, train loss = 1.206375, test loss = 1.228385.\n",
      "Cluster 1: epoch = 00150, train loss = 1.171602, test loss = 1.198574.\n",
      "Cluster 1: epoch = 00160, train loss = 1.139813, test loss = 1.171743.\n",
      "Cluster 1: epoch = 00170, train loss = 1.110759, test loss = 1.147631.\n",
      "Cluster 1: epoch = 00180, train loss = 1.084179, test loss = 1.125983.\n",
      "Cluster 1: epoch = 00190, train loss = 1.059810, test loss = 1.106525.\n",
      "Cluster 1: epoch = 00200, train loss = 1.037405, test loss = 1.089008.\n",
      "Cluster 1: epoch = 00210, train loss = 1.016728, test loss = 1.073199.\n",
      "Cluster 1: epoch = 00220, train loss = 0.997561, test loss = 1.058882.\n",
      "Cluster 1: epoch = 00230, train loss = 0.979707, test loss = 1.045855.\n",
      "Cluster 1: epoch = 00240, train loss = 0.962992, test loss = 1.033944.\n",
      "Cluster 1: epoch = 00250, train loss = 0.947257, test loss = 1.022988.\n",
      "Cluster 1: epoch = 00260, train loss = 0.932367, test loss = 1.012853.\n",
      "Cluster 1: epoch = 00270, train loss = 0.918200, test loss = 1.003418.\n",
      "Cluster 1: epoch = 00280, train loss = 0.904661, test loss = 0.994583.\n",
      "Cluster 1: epoch = 00290, train loss = 0.891659, test loss = 0.986263.\n",
      "Cluster 1: epoch = 00300, train loss = 0.879122, test loss = 0.978389.\n",
      "Cluster 1: epoch = 00310, train loss = 0.866990, test loss = 0.970889.\n",
      "Cluster 1: epoch = 00320, train loss = 0.855212, test loss = 0.963720.\n",
      "Cluster 1: epoch = 00330, train loss = 0.843749, test loss = 0.956843.\n",
      "Cluster 1: epoch = 00340, train loss = 0.832563, test loss = 0.950226.\n",
      "Cluster 1: epoch = 00350, train loss = 0.821631, test loss = 0.943836.\n",
      "Cluster 1: epoch = 00360, train loss = 0.810929, test loss = 0.937655.\n",
      "Cluster 1: epoch = 00370, train loss = 0.800437, test loss = 0.931658.\n",
      "Cluster 1: epoch = 00380, train loss = 0.790142, test loss = 0.925832.\n",
      "Cluster 1: epoch = 00390, train loss = 0.780033, test loss = 0.920167.\n",
      "Cluster 1: epoch = 00400, train loss = 0.770100, test loss = 0.914650.\n",
      "Cluster 1: epoch = 00410, train loss = 0.760335, test loss = 0.909279.\n",
      "Cluster 1: epoch = 00420, train loss = 0.750732, test loss = 0.904042.\n",
      "Cluster 1: epoch = 00430, train loss = 0.741286, test loss = 0.898935.\n",
      "Cluster 1: epoch = 00440, train loss = 0.731993, test loss = 0.893948.\n",
      "Cluster 1: epoch = 00450, train loss = 0.722848, test loss = 0.889087.\n",
      "Cluster 1: epoch = 00460, train loss = 0.713850, test loss = 0.884342.\n",
      "Cluster 1: epoch = 00470, train loss = 0.704996, test loss = 0.879710.\n",
      "Cluster 1: epoch = 00480, train loss = 0.696280, test loss = 0.875182.\n",
      "Cluster 1: epoch = 00490, train loss = 0.687704, test loss = 0.870760.\n",
      "Cluster 1: epoch = 00500, train loss = 0.679264, test loss = 0.866444.\n",
      "Cluster 1: epoch = 00510, train loss = 0.670961, test loss = 0.862227.\n",
      "Cluster 1: epoch = 00520, train loss = 0.662788, test loss = 0.858113.\n",
      "Cluster 1: epoch = 00530, train loss = 0.654747, test loss = 0.854103.\n",
      "Cluster 1: epoch = 00540, train loss = 0.646834, test loss = 0.850182.\n",
      "Cluster 1: epoch = 00550, train loss = 0.639048, test loss = 0.846349.\n",
      "Cluster 1: epoch = 00560, train loss = 0.631387, test loss = 0.842603.\n",
      "Cluster 1: epoch = 00570, train loss = 0.623847, test loss = 0.838948.\n",
      "Cluster 1: epoch = 00580, train loss = 0.616428, test loss = 0.835375.\n",
      "Cluster 1: epoch = 00590, train loss = 0.609127, test loss = 0.831883.\n",
      "Cluster 1: epoch = 00600, train loss = 0.601942, test loss = 0.828464.\n",
      "Cluster 1: epoch = 00610, train loss = 0.594870, test loss = 0.825127.\n",
      "Cluster 1: epoch = 00620, train loss = 0.587911, test loss = 0.821869.\n",
      "Cluster 1: epoch = 00630, train loss = 0.581062, test loss = 0.818687.\n",
      "Cluster 1: epoch = 00640, train loss = 0.574320, test loss = 0.815584.\n",
      "Cluster 1: epoch = 00650, train loss = 0.567685, test loss = 0.812552.\n",
      "Cluster 1: epoch = 00660, train loss = 0.561155, test loss = 0.809588.\n",
      "Cluster 1: epoch = 00670, train loss = 0.554729, test loss = 0.806681.\n",
      "Cluster 1: epoch = 00680, train loss = 0.548402, test loss = 0.803839.\n",
      "Cluster 1: epoch = 00690, train loss = 0.542172, test loss = 0.801058.\n",
      "Cluster 1: epoch = 00700, train loss = 0.536041, test loss = 0.798337.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1 done in 0:00:01.371756.\n",
      "Writing the output model to \"./regularized_synonym_phi.k1.trained\".\n",
      "./regularized_synonym_phi.k2.trained\n",
      "Cluster 2: 297 train items and 83 test items available; using 1 steps of 297 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cluster 2: epoch = 00001, train loss = 1.921374, test loss = 1.899942.\n",
      "Cluster 2: epoch = 00010, train loss = 1.795945, test loss = 1.777717.\n",
      "Cluster 2: epoch = 00020, train loss = 1.611613, test loss = 1.598360.\n",
      "Cluster 2: epoch = 00030, train loss = 1.429246, test loss = 1.421304.\n",
      "Cluster 2: epoch = 00040, train loss = 1.270678, test loss = 1.267837.\n",
      "Cluster 2: epoch = 00050, train loss = 1.143804, test loss = 1.145611.\n",
      "Cluster 2: epoch = 00060, train loss = 1.048172, test loss = 1.054105.\n",
      "Cluster 2: epoch = 00070, train loss = 0.978980, test loss = 0.988549.\n",
      "Cluster 2: epoch = 00080, train loss = 0.929947, test loss = 0.942745.\n",
      "Cluster 2: epoch = 00090, train loss = 0.895068, test loss = 0.910778.\n",
      "Cluster 2: epoch = 00100, train loss = 0.869457, test loss = 0.887847.\n",
      "Cluster 2: epoch = 00110, train loss = 0.849551, test loss = 0.870452.\n",
      "Cluster 2: epoch = 00120, train loss = 0.832966, test loss = 0.856264.\n",
      "Cluster 2: epoch = 00130, train loss = 0.818227, test loss = 0.843846.\n",
      "Cluster 2: epoch = 00140, train loss = 0.804479, test loss = 0.832368.\n",
      "Cluster 2: epoch = 00150, train loss = 0.791265, test loss = 0.821390.\n",
      "Cluster 2: epoch = 00160, train loss = 0.778353, test loss = 0.810693.\n",
      "Cluster 2: epoch = 00170, train loss = 0.765641, test loss = 0.800181.\n",
      "Cluster 2: epoch = 00180, train loss = 0.753093, test loss = 0.789823.\n",
      "Cluster 2: epoch = 00190, train loss = 0.740701, test loss = 0.779614.\n",
      "Cluster 2: epoch = 00200, train loss = 0.728470, test loss = 0.769558.\n",
      "Cluster 2: epoch = 00210, train loss = 0.716412, test loss = 0.759666.\n",
      "Cluster 2: epoch = 00220, train loss = 0.704540, test loss = 0.749950.\n",
      "Cluster 2: epoch = 00230, train loss = 0.692861, test loss = 0.740415.\n",
      "Cluster 2: epoch = 00240, train loss = 0.681384, test loss = 0.731071.\n",
      "Cluster 2: epoch = 00250, train loss = 0.670117, test loss = 0.721920.\n",
      "Cluster 2: epoch = 00260, train loss = 0.659065, test loss = 0.712969.\n",
      "Cluster 2: epoch = 00270, train loss = 0.648233, test loss = 0.704221.\n",
      "Cluster 2: epoch = 00280, train loss = 0.637620, test loss = 0.695673.\n",
      "Cluster 2: epoch = 00290, train loss = 0.627230, test loss = 0.687325.\n",
      "Cluster 2: epoch = 00300, train loss = 0.617062, test loss = 0.679178.\n",
      "Cluster 2: epoch = 00310, train loss = 0.607114, test loss = 0.671231.\n",
      "Cluster 2: epoch = 00320, train loss = 0.597386, test loss = 0.663480.\n",
      "Cluster 2: epoch = 00330, train loss = 0.587875, test loss = 0.655923.\n",
      "Cluster 2: epoch = 00340, train loss = 0.578579, test loss = 0.648556.\n",
      "Cluster 2: epoch = 00350, train loss = 0.569494, test loss = 0.641374.\n",
      "Cluster 2: epoch = 00360, train loss = 0.560616, test loss = 0.634375.\n",
      "Cluster 2: epoch = 00370, train loss = 0.551942, test loss = 0.627554.\n",
      "Cluster 2: epoch = 00380, train loss = 0.543467, test loss = 0.620905.\n",
      "Cluster 2: epoch = 00390, train loss = 0.535186, test loss = 0.614426.\n",
      "Cluster 2: epoch = 00400, train loss = 0.527095, test loss = 0.608111.\n",
      "Cluster 2: epoch = 00410, train loss = 0.519189, test loss = 0.601953.\n",
      "Cluster 2: epoch = 00420, train loss = 0.511465, test loss = 0.595949.\n",
      "Cluster 2: epoch = 00430, train loss = 0.503917, test loss = 0.590096.\n",
      "Cluster 2: epoch = 00440, train loss = 0.496539, test loss = 0.584387.\n",
      "Cluster 2: epoch = 00450, train loss = 0.489328, test loss = 0.578820.\n",
      "Cluster 2: epoch = 00460, train loss = 0.482280, test loss = 0.573390.\n",
      "Cluster 2: epoch = 00470, train loss = 0.475388, test loss = 0.568091.\n",
      "Cluster 2: epoch = 00480, train loss = 0.468649, test loss = 0.562918.\n",
      "Cluster 2: epoch = 00490, train loss = 0.462058, test loss = 0.557865.\n",
      "Cluster 2: epoch = 00500, train loss = 0.455612, test loss = 0.552934.\n",
      "Cluster 2: epoch = 00510, train loss = 0.449306, test loss = 0.548117.\n",
      "Cluster 2: epoch = 00520, train loss = 0.443134, test loss = 0.543409.\n",
      "Cluster 2: epoch = 00530, train loss = 0.437095, test loss = 0.538808.\n",
      "Cluster 2: epoch = 00540, train loss = 0.431184, test loss = 0.534311.\n",
      "Cluster 2: epoch = 00550, train loss = 0.425396, test loss = 0.529912.\n",
      "Cluster 2: epoch = 00560, train loss = 0.419730, test loss = 0.525610.\n",
      "Cluster 2: epoch = 00570, train loss = 0.414179, test loss = 0.521402.\n",
      "Cluster 2: epoch = 00580, train loss = 0.408743, test loss = 0.517284.\n",
      "Cluster 2: epoch = 00590, train loss = 0.403416, test loss = 0.513253.\n",
      "Cluster 2: epoch = 00600, train loss = 0.398197, test loss = 0.509306.\n",
      "Cluster 2: epoch = 00610, train loss = 0.393082, test loss = 0.505440.\n",
      "Cluster 2: epoch = 00620, train loss = 0.388068, test loss = 0.501651.\n",
      "Cluster 2: epoch = 00630, train loss = 0.383152, test loss = 0.497940.\n",
      "Cluster 2: epoch = 00640, train loss = 0.378332, test loss = 0.494300.\n",
      "Cluster 2: epoch = 00650, train loss = 0.373604, test loss = 0.490734.\n",
      "Cluster 2: epoch = 00660, train loss = 0.368967, test loss = 0.487236.\n",
      "Cluster 2: epoch = 00670, train loss = 0.364418, test loss = 0.483805.\n",
      "Cluster 2: epoch = 00680, train loss = 0.359954, test loss = 0.480438.\n",
      "Cluster 2: epoch = 00690, train loss = 0.355573, test loss = 0.477133.\n",
      "Cluster 2: epoch = 00700, train loss = 0.351274, test loss = 0.473890.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 2 done in 0:00:02.666215.\n",
      "Writing the output model to \"./regularized_synonym_phi.k2.trained\".\n",
      "./regularized_synonym_phi.k3.trained\n",
      "Cluster 3: 100 train items and 20 test items available; using 1 steps of 100 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cluster 3: epoch = 00001, train loss = 1.880083, test loss = 1.814680.\n",
      "Cluster 3: epoch = 00010, train loss = 1.842329, test loss = 1.780739.\n",
      "Cluster 3: epoch = 00020, train loss = 1.778956, test loss = 1.723965.\n",
      "Cluster 3: epoch = 00030, train loss = 1.705124, test loss = 1.658130.\n",
      "Cluster 3: epoch = 00040, train loss = 1.627207, test loss = 1.589065.\n",
      "Cluster 3: epoch = 00050, train loss = 1.549303, test loss = 1.520514.\n",
      "Cluster 3: epoch = 00060, train loss = 1.474126, test loss = 1.454945.\n",
      "Cluster 3: epoch = 00070, train loss = 1.403388, test loss = 1.393896.\n",
      "Cluster 3: epoch = 00080, train loss = 1.338075, test loss = 1.338229.\n",
      "Cluster 3: epoch = 00090, train loss = 1.278636, test loss = 1.288316.\n",
      "Cluster 3: epoch = 00100, train loss = 1.225132, test loss = 1.244155.\n",
      "Cluster 3: epoch = 00110, train loss = 1.177350, test loss = 1.205505.\n",
      "Cluster 3: epoch = 00120, train loss = 1.134901, test loss = 1.171955.\n",
      "Cluster 3: epoch = 00130, train loss = 1.097295, test loss = 1.143007.\n",
      "Cluster 3: epoch = 00140, train loss = 1.063993, test loss = 1.118122.\n",
      "Cluster 3: epoch = 00150, train loss = 1.034447, test loss = 1.096762.\n",
      "Cluster 3: epoch = 00160, train loss = 1.008117, test loss = 1.078390.\n",
      "Cluster 3: epoch = 00170, train loss = 0.984513, test loss = 1.062533.\n",
      "Cluster 3: epoch = 00180, train loss = 0.963200, test loss = 1.048762.\n",
      "Cluster 3: epoch = 00190, train loss = 0.943791, test loss = 1.036697.\n",
      "Cluster 3: epoch = 00200, train loss = 0.925945, test loss = 1.026011.\n",
      "Cluster 3: epoch = 00210, train loss = 0.909381, test loss = 1.016432.\n",
      "Cluster 3: epoch = 00220, train loss = 0.893874, test loss = 1.007747.\n",
      "Cluster 3: epoch = 00230, train loss = 0.879225, test loss = 0.999760.\n",
      "Cluster 3: epoch = 00240, train loss = 0.865282, test loss = 0.992336.\n",
      "Cluster 3: epoch = 00250, train loss = 0.851921, test loss = 0.985348.\n",
      "Cluster 3: epoch = 00260, train loss = 0.839050, test loss = 0.978710.\n",
      "Cluster 3: epoch = 00270, train loss = 0.826596, test loss = 0.972356.\n",
      "Cluster 3: epoch = 00280, train loss = 0.814502, test loss = 0.966243.\n",
      "Cluster 3: epoch = 00290, train loss = 0.802726, test loss = 0.960331.\n",
      "Cluster 3: epoch = 00300, train loss = 0.791233, test loss = 0.954589.\n",
      "Cluster 3: epoch = 00310, train loss = 0.780001, test loss = 0.948994.\n",
      "Cluster 3: epoch = 00320, train loss = 0.769011, test loss = 0.943532.\n",
      "Cluster 3: epoch = 00330, train loss = 0.758252, test loss = 0.938196.\n",
      "Cluster 3: epoch = 00340, train loss = 0.747711, test loss = 0.932985.\n",
      "Cluster 3: epoch = 00350, train loss = 0.737381, test loss = 0.927878.\n",
      "Cluster 3: epoch = 00360, train loss = 0.727256, test loss = 0.922879.\n",
      "Cluster 3: epoch = 00370, train loss = 0.717332, test loss = 0.917983.\n",
      "Cluster 3: epoch = 00380, train loss = 0.707605, test loss = 0.913184.\n",
      "Cluster 3: epoch = 00390, train loss = 0.698068, test loss = 0.908485.\n",
      "Cluster 3: epoch = 00400, train loss = 0.688720, test loss = 0.903894.\n",
      "Cluster 3: epoch = 00410, train loss = 0.679557, test loss = 0.899403.\n",
      "Cluster 3: epoch = 00420, train loss = 0.670576, test loss = 0.895001.\n",
      "Cluster 3: epoch = 00430, train loss = 0.661774, test loss = 0.890701.\n",
      "Cluster 3: epoch = 00440, train loss = 0.653149, test loss = 0.886500.\n",
      "Cluster 3: epoch = 00450, train loss = 0.644696, test loss = 0.882378.\n",
      "Cluster 3: epoch = 00460, train loss = 0.636411, test loss = 0.878352.\n",
      "Cluster 3: epoch = 00470, train loss = 0.628293, test loss = 0.874421.\n",
      "Cluster 3: epoch = 00480, train loss = 0.620336, test loss = 0.870568.\n",
      "Cluster 3: epoch = 00490, train loss = 0.612538, test loss = 0.866806.\n",
      "Cluster 3: epoch = 00500, train loss = 0.604896, test loss = 0.863131.\n",
      "Cluster 3: epoch = 00510, train loss = 0.597406, test loss = 0.859530.\n",
      "Cluster 3: epoch = 00520, train loss = 0.590064, test loss = 0.856001.\n",
      "Cluster 3: epoch = 00530, train loss = 0.582867, test loss = 0.852554.\n",
      "Cluster 3: epoch = 00540, train loss = 0.575811, test loss = 0.849189.\n",
      "Cluster 3: epoch = 00550, train loss = 0.568894, test loss = 0.845894.\n",
      "Cluster 3: epoch = 00560, train loss = 0.562112, test loss = 0.842671.\n",
      "Cluster 3: epoch = 00570, train loss = 0.555463, test loss = 0.839518.\n",
      "Cluster 3: epoch = 00580, train loss = 0.548942, test loss = 0.836426.\n",
      "Cluster 3: epoch = 00590, train loss = 0.542546, test loss = 0.833405.\n",
      "Cluster 3: epoch = 00600, train loss = 0.536272, test loss = 0.830451.\n",
      "Cluster 3: epoch = 00610, train loss = 0.530117, test loss = 0.827551.\n",
      "Cluster 3: epoch = 00620, train loss = 0.524078, test loss = 0.824709.\n",
      "Cluster 3: epoch = 00630, train loss = 0.518152, test loss = 0.821923.\n",
      "Cluster 3: epoch = 00640, train loss = 0.512336, test loss = 0.819195.\n",
      "Cluster 3: epoch = 00650, train loss = 0.506628, test loss = 0.816525.\n",
      "Cluster 3: epoch = 00660, train loss = 0.501025, test loss = 0.813910.\n",
      "Cluster 3: epoch = 00670, train loss = 0.495525, test loss = 0.811343.\n",
      "Cluster 3: epoch = 00680, train loss = 0.490123, test loss = 0.808823.\n",
      "Cluster 3: epoch = 00690, train loss = 0.484820, test loss = 0.806350.\n",
      "Cluster 3: epoch = 00700, train loss = 0.479612, test loss = 0.803917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 3 done in 0:00:01.491885.\n",
      "Writing the output model to \"./regularized_synonym_phi.k3.trained\".\n",
      "./regularized_synonym_phi.k4.trained\n",
      "Cluster 4: 365 train items and 77 test items available; using 1 steps of 365 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cluster 4: epoch = 00001, train loss = 1.833213, test loss = 1.823331.\n",
      "Cluster 4: epoch = 00010, train loss = 1.685452, test loss = 1.675573.\n",
      "Cluster 4: epoch = 00020, train loss = 1.478963, test loss = 1.469347.\n",
      "Cluster 4: epoch = 00030, train loss = 1.287797, test loss = 1.278825.\n",
      "Cluster 4: epoch = 00040, train loss = 1.134799, test loss = 1.126890.\n",
      "Cluster 4: epoch = 00050, train loss = 1.023846, test loss = 1.017403.\n",
      "Cluster 4: epoch = 00060, train loss = 0.948770, test loss = 0.944145.\n",
      "Cluster 4: epoch = 00070, train loss = 0.899824, test loss = 0.897294.\n",
      "Cluster 4: epoch = 00080, train loss = 0.867703, test loss = 0.867473.\n",
      "Cluster 4: epoch = 00090, train loss = 0.845330, test loss = 0.847533.\n",
      "Cluster 4: epoch = 00100, train loss = 0.828086, test loss = 0.832805.\n",
      "Cluster 4: epoch = 00110, train loss = 0.813311, test loss = 0.820591.\n",
      "Cluster 4: epoch = 00120, train loss = 0.799639, test loss = 0.809503.\n",
      "Cluster 4: epoch = 00130, train loss = 0.786439, test loss = 0.798892.\n",
      "Cluster 4: epoch = 00140, train loss = 0.773454, test loss = 0.788499.\n",
      "Cluster 4: epoch = 00150, train loss = 0.760601, test loss = 0.778234.\n",
      "Cluster 4: epoch = 00160, train loss = 0.747863, test loss = 0.768083.\n",
      "Cluster 4: epoch = 00170, train loss = 0.735254, test loss = 0.758054.\n",
      "Cluster 4: epoch = 00180, train loss = 0.722790, test loss = 0.748165.\n",
      "Cluster 4: epoch = 00190, train loss = 0.710491, test loss = 0.738435.\n",
      "Cluster 4: epoch = 00200, train loss = 0.698375, test loss = 0.728874.\n",
      "Cluster 4: epoch = 00210, train loss = 0.686453, test loss = 0.719496.\n",
      "Cluster 4: epoch = 00220, train loss = 0.674741, test loss = 0.710308.\n",
      "Cluster 4: epoch = 00230, train loss = 0.663246, test loss = 0.701313.\n",
      "Cluster 4: epoch = 00240, train loss = 0.651974, test loss = 0.692517.\n",
      "Cluster 4: epoch = 00250, train loss = 0.640932, test loss = 0.683922.\n",
      "Cluster 4: epoch = 00260, train loss = 0.630124, test loss = 0.675528.\n",
      "Cluster 4: epoch = 00270, train loss = 0.619549, test loss = 0.667334.\n",
      "Cluster 4: epoch = 00280, train loss = 0.609209, test loss = 0.659342.\n",
      "Cluster 4: epoch = 00290, train loss = 0.599103, test loss = 0.651546.\n",
      "Cluster 4: epoch = 00300, train loss = 0.589230, test loss = 0.643942.\n",
      "Cluster 4: epoch = 00310, train loss = 0.579587, test loss = 0.636531.\n",
      "Cluster 4: epoch = 00320, train loss = 0.570171, test loss = 0.629308.\n",
      "Cluster 4: epoch = 00330, train loss = 0.560978, test loss = 0.622269.\n",
      "Cluster 4: epoch = 00340, train loss = 0.552005, test loss = 0.615408.\n",
      "Cluster 4: epoch = 00350, train loss = 0.543246, test loss = 0.608716.\n",
      "Cluster 4: epoch = 00360, train loss = 0.534697, test loss = 0.602191.\n",
      "Cluster 4: epoch = 00370, train loss = 0.526353, test loss = 0.595829.\n",
      "Cluster 4: epoch = 00380, train loss = 0.518209, test loss = 0.589627.\n",
      "Cluster 4: epoch = 00390, train loss = 0.510260, test loss = 0.583577.\n",
      "Cluster 4: epoch = 00400, train loss = 0.502499, test loss = 0.577676.\n",
      "Cluster 4: epoch = 00410, train loss = 0.494923, test loss = 0.571919.\n",
      "Cluster 4: epoch = 00420, train loss = 0.487525, test loss = 0.566296.\n",
      "Cluster 4: epoch = 00430, train loss = 0.480300, test loss = 0.560806.\n",
      "Cluster 4: epoch = 00440, train loss = 0.473243, test loss = 0.555445.\n",
      "Cluster 4: epoch = 00450, train loss = 0.466350, test loss = 0.550208.\n",
      "Cluster 4: epoch = 00460, train loss = 0.459614, test loss = 0.545092.\n",
      "Cluster 4: epoch = 00470, train loss = 0.453032, test loss = 0.540089.\n",
      "Cluster 4: epoch = 00480, train loss = 0.446598, test loss = 0.535197.\n",
      "Cluster 4: epoch = 00490, train loss = 0.440308, test loss = 0.530414.\n",
      "Cluster 4: epoch = 00500, train loss = 0.434157, test loss = 0.525733.\n",
      "Cluster 4: epoch = 00510, train loss = 0.428140, test loss = 0.521153.\n",
      "Cluster 4: epoch = 00520, train loss = 0.422255, test loss = 0.516666.\n",
      "Cluster 4: epoch = 00530, train loss = 0.416496, test loss = 0.512274.\n",
      "Cluster 4: epoch = 00540, train loss = 0.410860, test loss = 0.507971.\n",
      "Cluster 4: epoch = 00550, train loss = 0.405343, test loss = 0.503755.\n",
      "Cluster 4: epoch = 00560, train loss = 0.399941, test loss = 0.499621.\n",
      "Cluster 4: epoch = 00570, train loss = 0.394651, test loss = 0.495569.\n",
      "Cluster 4: epoch = 00580, train loss = 0.389470, test loss = 0.491594.\n",
      "Cluster 4: epoch = 00590, train loss = 0.384394, test loss = 0.487699.\n",
      "Cluster 4: epoch = 00600, train loss = 0.379420, test loss = 0.483875.\n",
      "Cluster 4: epoch = 00610, train loss = 0.374546, test loss = 0.480122.\n",
      "Cluster 4: epoch = 00620, train loss = 0.369768, test loss = 0.476435.\n",
      "Cluster 4: epoch = 00630, train loss = 0.365083, test loss = 0.472816.\n",
      "Cluster 4: epoch = 00640, train loss = 0.360489, test loss = 0.469263.\n",
      "Cluster 4: epoch = 00650, train loss = 0.355984, test loss = 0.465772.\n",
      "Cluster 4: epoch = 00660, train loss = 0.351564, test loss = 0.462340.\n",
      "Cluster 4: epoch = 00670, train loss = 0.347229, test loss = 0.458968.\n",
      "Cluster 4: epoch = 00680, train loss = 0.342974, test loss = 0.455654.\n",
      "Cluster 4: epoch = 00690, train loss = 0.338799, test loss = 0.452394.\n",
      "Cluster 4: epoch = 00700, train loss = 0.334701, test loss = 0.449190.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 4 done in 0:00:03.157650.\n",
      "Writing the output model to \"./regularized_synonym_phi.k4.trained\".\n",
      "./regularized_synonym_phi.k5.trained\n",
      "Cluster 5: 914 train items and 227 test items available; using 1 steps of 914 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cluster 5: epoch = 00001, train loss = 1.949737, test loss = 1.936610.\n",
      "Cluster 5: epoch = 00010, train loss = 1.806956, test loss = 1.796306.\n",
      "Cluster 5: epoch = 00020, train loss = 1.631788, test loss = 1.625439.\n",
      "Cluster 5: epoch = 00030, train loss = 1.488152, test loss = 1.486920.\n",
      "Cluster 5: epoch = 00040, train loss = 1.385084, test loss = 1.389516.\n",
      "Cluster 5: epoch = 00050, train loss = 1.315053, test loss = 1.325607.\n",
      "Cluster 5: epoch = 00060, train loss = 1.266150, test loss = 1.283220.\n",
      "Cluster 5: epoch = 00070, train loss = 1.228637, test loss = 1.252528.\n",
      "Cluster 5: epoch = 00080, train loss = 1.196651, test loss = 1.227553.\n",
      "Cluster 5: epoch = 00090, train loss = 1.167330, test loss = 1.205320.\n",
      "Cluster 5: epoch = 00100, train loss = 1.139476, test loss = 1.184535.\n",
      "Cluster 5: epoch = 00110, train loss = 1.112644, test loss = 1.164675.\n",
      "Cluster 5: epoch = 00120, train loss = 1.086683, test loss = 1.145540.\n",
      "Cluster 5: epoch = 00130, train loss = 1.061552, test loss = 1.127062.\n",
      "Cluster 5: epoch = 00140, train loss = 1.037243, test loss = 1.109210.\n",
      "Cluster 5: epoch = 00150, train loss = 1.013752, test loss = 1.091964.\n",
      "Cluster 5: epoch = 00160, train loss = 0.991073, test loss = 1.075306.\n",
      "Cluster 5: epoch = 00170, train loss = 0.969192, test loss = 1.059225.\n",
      "Cluster 5: epoch = 00180, train loss = 0.948087, test loss = 1.043701.\n",
      "Cluster 5: epoch = 00190, train loss = 0.927739, test loss = 1.028715.\n",
      "Cluster 5: epoch = 00200, train loss = 0.908121, test loss = 1.014248.\n",
      "Cluster 5: epoch = 00210, train loss = 0.889205, test loss = 1.000273.\n",
      "Cluster 5: epoch = 00220, train loss = 0.870963, test loss = 0.986771.\n",
      "Cluster 5: epoch = 00230, train loss = 0.853370, test loss = 0.973720.\n",
      "Cluster 5: epoch = 00240, train loss = 0.836397, test loss = 0.961103.\n",
      "Cluster 5: epoch = 00250, train loss = 0.820020, test loss = 0.948895.\n",
      "Cluster 5: epoch = 00260, train loss = 0.804213, test loss = 0.937080.\n",
      "Cluster 5: epoch = 00270, train loss = 0.788953, test loss = 0.925641.\n",
      "Cluster 5: epoch = 00280, train loss = 0.774218, test loss = 0.914561.\n",
      "Cluster 5: epoch = 00290, train loss = 0.759985, test loss = 0.903818.\n",
      "Cluster 5: epoch = 00300, train loss = 0.746234, test loss = 0.893405.\n",
      "Cluster 5: epoch = 00310, train loss = 0.732945, test loss = 0.883304.\n",
      "Cluster 5: epoch = 00320, train loss = 0.720100, test loss = 0.873504.\n",
      "Cluster 5: epoch = 00330, train loss = 0.707680, test loss = 0.863992.\n",
      "Cluster 5: epoch = 00340, train loss = 0.695669, test loss = 0.854755.\n",
      "Cluster 5: epoch = 00350, train loss = 0.684050, test loss = 0.845786.\n",
      "Cluster 5: epoch = 00360, train loss = 0.672809, test loss = 0.837072.\n",
      "Cluster 5: epoch = 00370, train loss = 0.661930, test loss = 0.828599.\n",
      "Cluster 5: epoch = 00380, train loss = 0.651399, test loss = 0.820363.\n",
      "Cluster 5: epoch = 00390, train loss = 0.641203, test loss = 0.812358.\n",
      "Cluster 5: epoch = 00400, train loss = 0.631329, test loss = 0.804573.\n",
      "Cluster 5: epoch = 00410, train loss = 0.621765, test loss = 0.796998.\n",
      "Cluster 5: epoch = 00420, train loss = 0.612498, test loss = 0.789619.\n",
      "Cluster 5: epoch = 00430, train loss = 0.603518, test loss = 0.782433.\n",
      "Cluster 5: epoch = 00440, train loss = 0.594814, test loss = 0.775442.\n",
      "Cluster 5: epoch = 00450, train loss = 0.586376, test loss = 0.768636.\n",
      "Cluster 5: epoch = 00460, train loss = 0.578193, test loss = 0.762000.\n",
      "Cluster 5: epoch = 00470, train loss = 0.570256, test loss = 0.755535.\n",
      "Cluster 5: epoch = 00480, train loss = 0.562557, test loss = 0.749231.\n",
      "Cluster 5: epoch = 00490, train loss = 0.555087, test loss = 0.743087.\n",
      "Cluster 5: epoch = 00500, train loss = 0.547836, test loss = 0.737092.\n",
      "Cluster 5: epoch = 00510, train loss = 0.540798, test loss = 0.731249.\n",
      "Cluster 5: epoch = 00520, train loss = 0.533964, test loss = 0.725553.\n",
      "Cluster 5: epoch = 00530, train loss = 0.527328, test loss = 0.719994.\n",
      "Cluster 5: epoch = 00540, train loss = 0.520881, test loss = 0.714565.\n",
      "Cluster 5: epoch = 00550, train loss = 0.514619, test loss = 0.709265.\n",
      "Cluster 5: epoch = 00560, train loss = 0.508534, test loss = 0.704093.\n",
      "Cluster 5: epoch = 00570, train loss = 0.502619, test loss = 0.699046.\n",
      "Cluster 5: epoch = 00580, train loss = 0.496869, test loss = 0.694115.\n",
      "Cluster 5: epoch = 00590, train loss = 0.491278, test loss = 0.689297.\n",
      "Cluster 5: epoch = 00600, train loss = 0.485842, test loss = 0.684592.\n",
      "Cluster 5: epoch = 00610, train loss = 0.480553, test loss = 0.679991.\n",
      "Cluster 5: epoch = 00620, train loss = 0.475408, test loss = 0.675497.\n",
      "Cluster 5: epoch = 00630, train loss = 0.470402, test loss = 0.671108.\n",
      "Cluster 5: epoch = 00640, train loss = 0.465530, test loss = 0.666815.\n",
      "Cluster 5: epoch = 00650, train loss = 0.460786, test loss = 0.662618.\n",
      "Cluster 5: epoch = 00660, train loss = 0.456169, test loss = 0.658510.\n",
      "Cluster 5: epoch = 00670, train loss = 0.451672, test loss = 0.654493.\n",
      "Cluster 5: epoch = 00680, train loss = 0.447292, test loss = 0.650567.\n",
      "Cluster 5: epoch = 00690, train loss = 0.443026, test loss = 0.646729.\n",
      "Cluster 5: epoch = 00700, train loss = 0.438868, test loss = 0.642972.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 5 done in 0:00:09.522011.\n",
      "Writing the output model to \"./regularized_synonym_phi.k5.trained\".\n",
      "./regularized_synonym_phi.k6.trained\n",
      "Cluster 6: 77 train items and 16 test items available; using 1 steps of 77 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cluster 6: epoch = 00001, train loss = 1.900649, test loss = 1.890868.\n",
      "Cluster 6: epoch = 00010, train loss = 1.847999, test loss = 1.841430.\n",
      "Cluster 6: epoch = 00020, train loss = 1.759486, test loss = 1.758317.\n",
      "Cluster 6: epoch = 00030, train loss = 1.656753, test loss = 1.661893.\n",
      "Cluster 6: epoch = 00040, train loss = 1.549186, test loss = 1.561005.\n",
      "Cluster 6: epoch = 00050, train loss = 1.442880, test loss = 1.461415.\n",
      "Cluster 6: epoch = 00060, train loss = 1.341848, test loss = 1.366911.\n",
      "Cluster 6: epoch = 00070, train loss = 1.248575, test loss = 1.279839.\n",
      "Cluster 6: epoch = 00080, train loss = 1.164409, test loss = 1.201470.\n",
      "Cluster 6: epoch = 00090, train loss = 1.089857, test loss = 1.132279.\n",
      "Cluster 6: epoch = 00100, train loss = 1.024831, test loss = 1.072177.\n",
      "Cluster 6: epoch = 00110, train loss = 0.968833, test loss = 1.020686.\n",
      "Cluster 6: epoch = 00120, train loss = 0.921110, test loss = 0.977086.\n",
      "Cluster 6: epoch = 00130, train loss = 0.880766, test loss = 0.940524.\n",
      "Cluster 6: epoch = 00140, train loss = 0.846856, test loss = 0.910101.\n",
      "Cluster 6: epoch = 00150, train loss = 0.818443, test loss = 0.884922.\n",
      "Cluster 6: epoch = 00160, train loss = 0.794645, test loss = 0.864149.\n",
      "Cluster 6: epoch = 00170, train loss = 0.774657, test loss = 0.847016.\n",
      "Cluster 6: epoch = 00180, train loss = 0.757769, test loss = 0.832846.\n",
      "Cluster 6: epoch = 00190, train loss = 0.743369, test loss = 0.821057.\n",
      "Cluster 6: epoch = 00200, train loss = 0.730939, test loss = 0.811156.\n",
      "Cluster 6: epoch = 00210, train loss = 0.720050, test loss = 0.802735.\n",
      "Cluster 6: epoch = 00220, train loss = 0.710354, test loss = 0.795461.\n",
      "Cluster 6: epoch = 00230, train loss = 0.701570, test loss = 0.789067.\n",
      "Cluster 6: epoch = 00240, train loss = 0.693478, test loss = 0.783344.\n",
      "Cluster 6: epoch = 00250, train loss = 0.685906, test loss = 0.778126.\n",
      "Cluster 6: epoch = 00260, train loss = 0.678723, test loss = 0.773289.\n",
      "Cluster 6: epoch = 00270, train loss = 0.671828, test loss = 0.768736.\n",
      "Cluster 6: epoch = 00280, train loss = 0.665147, test loss = 0.764395.\n",
      "Cluster 6: epoch = 00290, train loss = 0.658627, test loss = 0.760216.\n",
      "Cluster 6: epoch = 00300, train loss = 0.652227, test loss = 0.756158.\n",
      "Cluster 6: epoch = 00310, train loss = 0.645919, test loss = 0.752194.\n",
      "Cluster 6: epoch = 00320, train loss = 0.639684, test loss = 0.748305.\n",
      "Cluster 6: epoch = 00330, train loss = 0.633509, test loss = 0.744477.\n",
      "Cluster 6: epoch = 00340, train loss = 0.627384, test loss = 0.740702.\n",
      "Cluster 6: epoch = 00350, train loss = 0.621305, test loss = 0.736972.\n",
      "Cluster 6: epoch = 00360, train loss = 0.615269, test loss = 0.733285.\n",
      "Cluster 6: epoch = 00370, train loss = 0.609273, test loss = 0.729638.\n",
      "Cluster 6: epoch = 00380, train loss = 0.603318, test loss = 0.726030.\n",
      "Cluster 6: epoch = 00390, train loss = 0.597404, test loss = 0.722460.\n",
      "Cluster 6: epoch = 00400, train loss = 0.591531, test loss = 0.718928.\n",
      "Cluster 6: epoch = 00410, train loss = 0.585702, test loss = 0.715434.\n",
      "Cluster 6: epoch = 00420, train loss = 0.579915, test loss = 0.711979.\n",
      "Cluster 6: epoch = 00430, train loss = 0.574174, test loss = 0.708563.\n",
      "Cluster 6: epoch = 00440, train loss = 0.568480, test loss = 0.705186.\n",
      "Cluster 6: epoch = 00450, train loss = 0.562833, test loss = 0.701849.\n",
      "Cluster 6: epoch = 00460, train loss = 0.557234, test loss = 0.698552.\n",
      "Cluster 6: epoch = 00470, train loss = 0.551685, test loss = 0.695296.\n",
      "Cluster 6: epoch = 00480, train loss = 0.546186, test loss = 0.692080.\n",
      "Cluster 6: epoch = 00490, train loss = 0.540739, test loss = 0.688905.\n",
      "Cluster 6: epoch = 00500, train loss = 0.535343, test loss = 0.685771.\n",
      "Cluster 6: epoch = 00510, train loss = 0.530000, test loss = 0.682679.\n",
      "Cluster 6: epoch = 00520, train loss = 0.524710, test loss = 0.679627.\n",
      "Cluster 6: epoch = 00530, train loss = 0.519474, test loss = 0.676616.\n",
      "Cluster 6: epoch = 00540, train loss = 0.514292, test loss = 0.673647.\n",
      "Cluster 6: epoch = 00550, train loss = 0.509164, test loss = 0.670718.\n",
      "Cluster 6: epoch = 00560, train loss = 0.504091, test loss = 0.667830.\n",
      "Cluster 6: epoch = 00570, train loss = 0.499072, test loss = 0.664982.\n",
      "Cluster 6: epoch = 00580, train loss = 0.494108, test loss = 0.662175.\n",
      "Cluster 6: epoch = 00590, train loss = 0.489200, test loss = 0.659407.\n",
      "Cluster 6: epoch = 00600, train loss = 0.484346, test loss = 0.656679.\n",
      "Cluster 6: epoch = 00610, train loss = 0.479548, test loss = 0.653990.\n",
      "Cluster 6: epoch = 00620, train loss = 0.474803, test loss = 0.651341.\n",
      "Cluster 6: epoch = 00630, train loss = 0.470114, test loss = 0.648729.\n",
      "Cluster 6: epoch = 00640, train loss = 0.465479, test loss = 0.646156.\n",
      "Cluster 6: epoch = 00650, train loss = 0.460899, test loss = 0.643620.\n",
      "Cluster 6: epoch = 00660, train loss = 0.456372, test loss = 0.641122.\n",
      "Cluster 6: epoch = 00670, train loss = 0.451899, test loss = 0.638660.\n",
      "Cluster 6: epoch = 00680, train loss = 0.447480, test loss = 0.636235.\n",
      "Cluster 6: epoch = 00690, train loss = 0.443113, test loss = 0.633845.\n",
      "Cluster 6: epoch = 00700, train loss = 0.438800, test loss = 0.631491.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 6 done in 0:00:01.430950.\n",
      "Writing the output model to \"./regularized_synonym_phi.k6.trained\".\n",
      "./regularized_synonym_phi.k7.trained\n",
      "Cluster 7: 166 train items and 44 test items available; using 1 steps of 166 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cluster 7: epoch = 00001, train loss = 1.928384, test loss = 1.889552.\n",
      "Cluster 7: epoch = 00010, train loss = 1.845463, test loss = 1.810811.\n",
      "Cluster 7: epoch = 00020, train loss = 1.714119, test loss = 1.686234.\n",
      "Cluster 7: epoch = 00030, train loss = 1.571973, test loss = 1.551652.\n",
      "Cluster 7: epoch = 00040, train loss = 1.434603, test loss = 1.421912.\n",
      "Cluster 7: epoch = 00050, train loss = 1.310542, test loss = 1.305141.\n",
      "Cluster 7: epoch = 00060, train loss = 1.203721, test loss = 1.205058.\n",
      "Cluster 7: epoch = 00070, train loss = 1.114988, test loss = 1.122436.\n",
      "Cluster 7: epoch = 00080, train loss = 1.043261, test loss = 1.056203.\n",
      "Cluster 7: epoch = 00090, train loss = 0.986409, test loss = 1.004281.\n",
      "Cluster 7: epoch = 00100, train loss = 0.941882, test loss = 0.964204.\n",
      "Cluster 7: epoch = 00110, train loss = 0.907143, test loss = 0.933517.\n",
      "Cluster 7: epoch = 00120, train loss = 0.879877, test loss = 0.909988.\n",
      "Cluster 7: epoch = 00130, train loss = 0.858137, test loss = 0.891734.\n",
      "Cluster 7: epoch = 00140, train loss = 0.840357, test loss = 0.877252.\n",
      "Cluster 7: epoch = 00150, train loss = 0.825342, test loss = 0.865389.\n",
      "Cluster 7: epoch = 00160, train loss = 0.812209, test loss = 0.855302.\n",
      "Cluster 7: epoch = 00170, train loss = 0.800330, test loss = 0.846384.\n",
      "Cluster 7: epoch = 00180, train loss = 0.789271, test loss = 0.838224.\n",
      "Cluster 7: epoch = 00190, train loss = 0.778744, test loss = 0.830546.\n",
      "Cluster 7: epoch = 00200, train loss = 0.768564, test loss = 0.823175.\n",
      "Cluster 7: epoch = 00210, train loss = 0.758616, test loss = 0.816005.\n",
      "Cluster 7: epoch = 00220, train loss = 0.748829, test loss = 0.808976.\n",
      "Cluster 7: epoch = 00230, train loss = 0.739170, test loss = 0.802053.\n",
      "Cluster 7: epoch = 00240, train loss = 0.729615, test loss = 0.795217.\n",
      "Cluster 7: epoch = 00250, train loss = 0.720157, test loss = 0.788460.\n",
      "Cluster 7: epoch = 00260, train loss = 0.710795, test loss = 0.781782.\n",
      "Cluster 7: epoch = 00270, train loss = 0.701529, test loss = 0.775182.\n",
      "Cluster 7: epoch = 00280, train loss = 0.692362, test loss = 0.768668.\n",
      "Cluster 7: epoch = 00290, train loss = 0.683300, test loss = 0.762244.\n",
      "Cluster 7: epoch = 00300, train loss = 0.674346, test loss = 0.755912.\n",
      "Cluster 7: epoch = 00310, train loss = 0.665504, test loss = 0.749672.\n",
      "Cluster 7: epoch = 00320, train loss = 0.656777, test loss = 0.743527.\n",
      "Cluster 7: epoch = 00330, train loss = 0.648168, test loss = 0.737483.\n",
      "Cluster 7: epoch = 00340, train loss = 0.639679, test loss = 0.731539.\n",
      "Cluster 7: epoch = 00350, train loss = 0.631313, test loss = 0.725697.\n",
      "Cluster 7: epoch = 00360, train loss = 0.623070, test loss = 0.719959.\n",
      "Cluster 7: epoch = 00370, train loss = 0.614953, test loss = 0.714318.\n",
      "Cluster 7: epoch = 00380, train loss = 0.606963, test loss = 0.708782.\n",
      "Cluster 7: epoch = 00390, train loss = 0.599099, test loss = 0.703350.\n",
      "Cluster 7: epoch = 00400, train loss = 0.591360, test loss = 0.698019.\n",
      "Cluster 7: epoch = 00410, train loss = 0.583748, test loss = 0.692789.\n",
      "Cluster 7: epoch = 00420, train loss = 0.576262, test loss = 0.687659.\n",
      "Cluster 7: epoch = 00430, train loss = 0.568901, test loss = 0.682630.\n",
      "Cluster 7: epoch = 00440, train loss = 0.561664, test loss = 0.677699.\n",
      "Cluster 7: epoch = 00450, train loss = 0.554551, test loss = 0.672866.\n",
      "Cluster 7: epoch = 00460, train loss = 0.547560, test loss = 0.668124.\n",
      "Cluster 7: epoch = 00470, train loss = 0.540689, test loss = 0.663476.\n",
      "Cluster 7: epoch = 00480, train loss = 0.533937, test loss = 0.658921.\n",
      "Cluster 7: epoch = 00490, train loss = 0.527303, test loss = 0.654458.\n",
      "Cluster 7: epoch = 00500, train loss = 0.520786, test loss = 0.650086.\n",
      "Cluster 7: epoch = 00510, train loss = 0.514383, test loss = 0.645804.\n",
      "Cluster 7: epoch = 00520, train loss = 0.508093, test loss = 0.641607.\n",
      "Cluster 7: epoch = 00530, train loss = 0.501914, test loss = 0.637493.\n",
      "Cluster 7: epoch = 00540, train loss = 0.495844, test loss = 0.633457.\n",
      "Cluster 7: epoch = 00550, train loss = 0.489881, test loss = 0.629504.\n",
      "Cluster 7: epoch = 00560, train loss = 0.484024, test loss = 0.625628.\n",
      "Cluster 7: epoch = 00570, train loss = 0.478270, test loss = 0.621828.\n",
      "Cluster 7: epoch = 00580, train loss = 0.472618, test loss = 0.618104.\n",
      "Cluster 7: epoch = 00590, train loss = 0.467065, test loss = 0.614455.\n",
      "Cluster 7: epoch = 00600, train loss = 0.461610, test loss = 0.610877.\n",
      "Cluster 7: epoch = 00610, train loss = 0.456250, test loss = 0.607371.\n",
      "Cluster 7: epoch = 00620, train loss = 0.450984, test loss = 0.603933.\n",
      "Cluster 7: epoch = 00630, train loss = 0.445811, test loss = 0.600560.\n",
      "Cluster 7: epoch = 00640, train loss = 0.440727, test loss = 0.597251.\n",
      "Cluster 7: epoch = 00650, train loss = 0.435731, test loss = 0.594002.\n",
      "Cluster 7: epoch = 00660, train loss = 0.430823, test loss = 0.590812.\n",
      "Cluster 7: epoch = 00670, train loss = 0.425998, test loss = 0.587685.\n",
      "Cluster 7: epoch = 00680, train loss = 0.421256, test loss = 0.584618.\n",
      "Cluster 7: epoch = 00690, train loss = 0.416596, test loss = 0.581606.\n",
      "Cluster 7: epoch = 00700, train loss = 0.412015, test loss = 0.578653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 7 done in 0:00:01.876516.\n",
      "Writing the output model to \"./regularized_synonym_phi.k7.trained\".\n",
      "./regularized_synonym_phi.k8.trained\n",
      "Cluster 8: 91 train items and 19 test items available; using 1 steps of 91 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cluster 8: epoch = 00001, train loss = 1.886245, test loss = 1.919568.\n",
      "Cluster 8: epoch = 00010, train loss = 1.854327, test loss = 1.888782.\n",
      "Cluster 8: epoch = 00020, train loss = 1.800177, test loss = 1.836630.\n",
      "Cluster 8: epoch = 00030, train loss = 1.736276, test loss = 1.775228.\n",
      "Cluster 8: epoch = 00040, train loss = 1.667835, test loss = 1.709655.\n",
      "Cluster 8: epoch = 00050, train loss = 1.598255, test loss = 1.643239.\n",
      "Cluster 8: epoch = 00060, train loss = 1.529878, test loss = 1.578267.\n",
      "Cluster 8: epoch = 00070, train loss = 1.464291, test loss = 1.516282.\n",
      "Cluster 8: epoch = 00080, train loss = 1.402507, test loss = 1.458262.\n",
      "Cluster 8: epoch = 00090, train loss = 1.345112, test loss = 1.404764.\n",
      "Cluster 8: epoch = 00100, train loss = 1.292366, test loss = 1.356023.\n",
      "Cluster 8: epoch = 00110, train loss = 1.244298, test loss = 1.312047.\n",
      "Cluster 8: epoch = 00120, train loss = 1.200763, test loss = 1.272673.\n",
      "Cluster 8: epoch = 00130, train loss = 1.161499, test loss = 1.237622.\n",
      "Cluster 8: epoch = 00140, train loss = 1.126175, test loss = 1.206551.\n",
      "Cluster 8: epoch = 00150, train loss = 1.094416, test loss = 1.179071.\n",
      "Cluster 8: epoch = 00160, train loss = 1.065834, test loss = 1.154784.\n",
      "Cluster 8: epoch = 00170, train loss = 1.040044, test loss = 1.133292.\n",
      "Cluster 8: epoch = 00180, train loss = 1.016680, test loss = 1.114229.\n",
      "Cluster 8: epoch = 00190, train loss = 0.995406, test loss = 1.097248.\n",
      "Cluster 8: epoch = 00200, train loss = 0.975917, test loss = 1.082038.\n",
      "Cluster 8: epoch = 00210, train loss = 0.957940, test loss = 1.068323.\n",
      "Cluster 8: epoch = 00220, train loss = 0.941242, test loss = 1.055864.\n",
      "Cluster 8: epoch = 00230, train loss = 0.925617, test loss = 1.044458.\n",
      "Cluster 8: epoch = 00240, train loss = 0.910895, test loss = 1.033931.\n",
      "Cluster 8: epoch = 00250, train loss = 0.896932, test loss = 1.024136.\n",
      "Cluster 8: epoch = 00260, train loss = 0.883608, test loss = 1.014951.\n",
      "Cluster 8: epoch = 00270, train loss = 0.870821, test loss = 1.006275.\n",
      "Cluster 8: epoch = 00280, train loss = 0.858497, test loss = 0.998027.\n",
      "Cluster 8: epoch = 00290, train loss = 0.846570, test loss = 0.990146.\n",
      "Cluster 8: epoch = 00300, train loss = 0.834988, test loss = 0.982580.\n",
      "Cluster 8: epoch = 00310, train loss = 0.823711, test loss = 0.975288.\n",
      "Cluster 8: epoch = 00320, train loss = 0.812710, test loss = 0.968238.\n",
      "Cluster 8: epoch = 00330, train loss = 0.801956, test loss = 0.961402.\n",
      "Cluster 8: epoch = 00340, train loss = 0.791433, test loss = 0.954766.\n",
      "Cluster 8: epoch = 00350, train loss = 0.781123, test loss = 0.948314.\n",
      "Cluster 8: epoch = 00360, train loss = 0.771014, test loss = 0.942034.\n",
      "Cluster 8: epoch = 00370, train loss = 0.761097, test loss = 0.935911.\n",
      "Cluster 8: epoch = 00380, train loss = 0.751363, test loss = 0.929934.\n",
      "Cluster 8: epoch = 00390, train loss = 0.741806, test loss = 0.924103.\n",
      "Cluster 8: epoch = 00400, train loss = 0.732422, test loss = 0.918416.\n",
      "Cluster 8: epoch = 00410, train loss = 0.723205, test loss = 0.912861.\n",
      "Cluster 8: epoch = 00420, train loss = 0.714150, test loss = 0.907439.\n",
      "Cluster 8: epoch = 00430, train loss = 0.705254, test loss = 0.902143.\n",
      "Cluster 8: epoch = 00440, train loss = 0.696514, test loss = 0.896972.\n",
      "Cluster 8: epoch = 00450, train loss = 0.687927, test loss = 0.891916.\n",
      "Cluster 8: epoch = 00460, train loss = 0.679489, test loss = 0.886980.\n",
      "Cluster 8: epoch = 00470, train loss = 0.671198, test loss = 0.882157.\n",
      "Cluster 8: epoch = 00480, train loss = 0.663050, test loss = 0.877441.\n",
      "Cluster 8: epoch = 00490, train loss = 0.655042, test loss = 0.872831.\n",
      "Cluster 8: epoch = 00500, train loss = 0.647172, test loss = 0.868328.\n",
      "Cluster 8: epoch = 00510, train loss = 0.639437, test loss = 0.863928.\n",
      "Cluster 8: epoch = 00520, train loss = 0.631832, test loss = 0.859627.\n",
      "Cluster 8: epoch = 00530, train loss = 0.624355, test loss = 0.855422.\n",
      "Cluster 8: epoch = 00540, train loss = 0.617006, test loss = 0.851310.\n",
      "Cluster 8: epoch = 00550, train loss = 0.609780, test loss = 0.847290.\n",
      "Cluster 8: epoch = 00560, train loss = 0.602674, test loss = 0.843355.\n",
      "Cluster 8: epoch = 00570, train loss = 0.595686, test loss = 0.839512.\n",
      "Cluster 8: epoch = 00580, train loss = 0.588815, test loss = 0.835754.\n",
      "Cluster 8: epoch = 00590, train loss = 0.582055, test loss = 0.832076.\n",
      "Cluster 8: epoch = 00600, train loss = 0.575406, test loss = 0.828476.\n",
      "Cluster 8: epoch = 00610, train loss = 0.568866, test loss = 0.824951.\n",
      "Cluster 8: epoch = 00620, train loss = 0.562430, test loss = 0.821495.\n",
      "Cluster 8: epoch = 00630, train loss = 0.556097, test loss = 0.818112.\n",
      "Cluster 8: epoch = 00640, train loss = 0.549865, test loss = 0.814803.\n",
      "Cluster 8: epoch = 00650, train loss = 0.543732, test loss = 0.811559.\n",
      "Cluster 8: epoch = 00660, train loss = 0.537697, test loss = 0.808377.\n",
      "Cluster 8: epoch = 00670, train loss = 0.531755, test loss = 0.805261.\n",
      "Cluster 8: epoch = 00680, train loss = 0.525907, test loss = 0.802210.\n",
      "Cluster 8: epoch = 00690, train loss = 0.520148, test loss = 0.799216.\n",
      "Cluster 8: epoch = 00700, train loss = 0.514478, test loss = 0.796283.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 8 done in 0:00:01.513740.\n",
      "Writing the output model to \"./regularized_synonym_phi.k8.trained\".\n",
      "./regularized_synonym_phi.k9.trained\n",
      "Cluster 9: 291 train items and 82 test items available; using 1 steps of 291 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cluster 9: epoch = 00001, train loss = 1.876930, test loss = 1.849035.\n",
      "Cluster 9: epoch = 00010, train loss = 1.757930, test loss = 1.733898.\n",
      "Cluster 9: epoch = 00020, train loss = 1.582498, test loss = 1.564469.\n",
      "Cluster 9: epoch = 00030, train loss = 1.408461, test loss = 1.396851.\n",
      "Cluster 9: epoch = 00040, train loss = 1.256709, test loss = 1.251285.\n",
      "Cluster 9: epoch = 00050, train loss = 1.134921, test loss = 1.135145.\n",
      "Cluster 9: epoch = 00060, train loss = 1.042804, test loss = 1.048041.\n",
      "Cluster 9: epoch = 00070, train loss = 0.975887, test loss = 0.985527.\n",
      "Cluster 9: epoch = 00080, train loss = 0.928246, test loss = 0.941762.\n",
      "Cluster 9: epoch = 00090, train loss = 0.894185, test loss = 0.911151.\n",
      "Cluster 9: epoch = 00100, train loss = 0.869052, test loss = 0.889134.\n",
      "Cluster 9: epoch = 00110, train loss = 0.849436, test loss = 0.872383.\n",
      "Cluster 9: epoch = 00120, train loss = 0.833049, test loss = 0.858675.\n",
      "Cluster 9: epoch = 00130, train loss = 0.818466, test loss = 0.846631.\n",
      "Cluster 9: epoch = 00140, train loss = 0.804860, test loss = 0.835464.\n",
      "Cluster 9: epoch = 00150, train loss = 0.791779, test loss = 0.824753.\n",
      "Cluster 9: epoch = 00160, train loss = 0.779003, test loss = 0.814292.\n",
      "Cluster 9: epoch = 00170, train loss = 0.766425, test loss = 0.803995.\n",
      "Cluster 9: epoch = 00180, train loss = 0.754007, test loss = 0.793832.\n",
      "Cluster 9: epoch = 00190, train loss = 0.741745, test loss = 0.783805.\n",
      "Cluster 9: epoch = 00200, train loss = 0.729640, test loss = 0.773921.\n",
      "Cluster 9: epoch = 00210, train loss = 0.717704, test loss = 0.764191.\n",
      "Cluster 9: epoch = 00220, train loss = 0.705948, test loss = 0.754630.\n",
      "Cluster 9: epoch = 00230, train loss = 0.694380, test loss = 0.745245.\n",
      "Cluster 9: epoch = 00240, train loss = 0.683013, test loss = 0.736045.\n",
      "Cluster 9: epoch = 00250, train loss = 0.671849, test loss = 0.727036.\n",
      "Cluster 9: epoch = 00260, train loss = 0.660895, test loss = 0.718217.\n",
      "Cluster 9: epoch = 00270, train loss = 0.650156, test loss = 0.709592.\n",
      "Cluster 9: epoch = 00280, train loss = 0.639633, test loss = 0.701165.\n",
      "Cluster 9: epoch = 00290, train loss = 0.629329, test loss = 0.692935.\n",
      "Cluster 9: epoch = 00300, train loss = 0.619242, test loss = 0.684901.\n",
      "Cluster 9: epoch = 00310, train loss = 0.609374, test loss = 0.677060.\n",
      "Cluster 9: epoch = 00320, train loss = 0.599721, test loss = 0.669410.\n",
      "Cluster 9: epoch = 00330, train loss = 0.590281, test loss = 0.661949.\n",
      "Cluster 9: epoch = 00340, train loss = 0.581053, test loss = 0.654673.\n",
      "Cluster 9: epoch = 00350, train loss = 0.572032, test loss = 0.647579.\n",
      "Cluster 9: epoch = 00360, train loss = 0.563217, test loss = 0.640663.\n",
      "Cluster 9: epoch = 00370, train loss = 0.554602, test loss = 0.633922.\n",
      "Cluster 9: epoch = 00380, train loss = 0.546183, test loss = 0.627351.\n",
      "Cluster 9: epoch = 00390, train loss = 0.537957, test loss = 0.620945.\n",
      "Cluster 9: epoch = 00400, train loss = 0.529919, test loss = 0.614698.\n",
      "Cluster 9: epoch = 00410, train loss = 0.522064, test loss = 0.608605.\n",
      "Cluster 9: epoch = 00420, train loss = 0.514388, test loss = 0.602666.\n",
      "Cluster 9: epoch = 00430, train loss = 0.506886, test loss = 0.596875.\n",
      "Cluster 9: epoch = 00440, train loss = 0.499554, test loss = 0.591226.\n",
      "Cluster 9: epoch = 00450, train loss = 0.492387, test loss = 0.585713.\n",
      "Cluster 9: epoch = 00460, train loss = 0.485380, test loss = 0.580331.\n",
      "Cluster 9: epoch = 00470, train loss = 0.478530, test loss = 0.575079.\n",
      "Cluster 9: epoch = 00480, train loss = 0.471831, test loss = 0.569952.\n",
      "Cluster 9: epoch = 00490, train loss = 0.465278, test loss = 0.564944.\n",
      "Cluster 9: epoch = 00500, train loss = 0.458868, test loss = 0.560055.\n",
      "Cluster 9: epoch = 00510, train loss = 0.452599, test loss = 0.555279.\n",
      "Cluster 9: epoch = 00520, train loss = 0.446463, test loss = 0.550609.\n",
      "Cluster 9: epoch = 00530, train loss = 0.440458, test loss = 0.546046.\n",
      "Cluster 9: epoch = 00540, train loss = 0.434580, test loss = 0.541585.\n",
      "Cluster 9: epoch = 00550, train loss = 0.428825, test loss = 0.537220.\n",
      "Cluster 9: epoch = 00560, train loss = 0.423190, test loss = 0.532952.\n",
      "Cluster 9: epoch = 00570, train loss = 0.417672, test loss = 0.528776.\n",
      "Cluster 9: epoch = 00580, train loss = 0.412266, test loss = 0.524688.\n",
      "Cluster 9: epoch = 00590, train loss = 0.406970, test loss = 0.520685.\n",
      "Cluster 9: epoch = 00600, train loss = 0.401781, test loss = 0.516765.\n",
      "Cluster 9: epoch = 00610, train loss = 0.396694, test loss = 0.512926.\n",
      "Cluster 9: epoch = 00620, train loss = 0.391709, test loss = 0.509164.\n",
      "Cluster 9: epoch = 00630, train loss = 0.386821, test loss = 0.505476.\n",
      "Cluster 9: epoch = 00640, train loss = 0.382027, test loss = 0.501860.\n",
      "Cluster 9: epoch = 00650, train loss = 0.377327, test loss = 0.498313.\n",
      "Cluster 9: epoch = 00660, train loss = 0.372716, test loss = 0.494836.\n",
      "Cluster 9: epoch = 00670, train loss = 0.368192, test loss = 0.491427.\n",
      "Cluster 9: epoch = 00680, train loss = 0.363754, test loss = 0.488078.\n",
      "Cluster 9: epoch = 00690, train loss = 0.359398, test loss = 0.484793.\n",
      "Cluster 9: epoch = 00700, train loss = 0.355124, test loss = 0.481566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 9 done in 0:00:02.652234.\n",
      "Writing the output model to \"./regularized_synonym_phi.k9.trained\".\n",
      "./regularized_synonym_phi.k10.trained\n",
      "Cluster 10: 43 train items and 13 test items available; using 1 steps of 43 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cluster 10: epoch = 00001, train loss = 1.999352, test loss = 1.981120.\n",
      "Cluster 10: epoch = 00010, train loss = 1.973849, test loss = 1.957029.\n",
      "Cluster 10: epoch = 00020, train loss = 1.929464, test loss = 1.915172.\n",
      "Cluster 10: epoch = 00030, train loss = 1.875446, test loss = 1.864329.\n",
      "Cluster 10: epoch = 00040, train loss = 1.815490, test loss = 1.808022.\n",
      "Cluster 10: epoch = 00050, train loss = 1.752070, test loss = 1.748614.\n",
      "Cluster 10: epoch = 00060, train loss = 1.687012, test loss = 1.687847.\n",
      "Cluster 10: epoch = 00070, train loss = 1.621702, test loss = 1.627047.\n",
      "Cluster 10: epoch = 00080, train loss = 1.557210, test loss = 1.567232.\n",
      "Cluster 10: epoch = 00090, train loss = 1.494338, test loss = 1.509166.\n",
      "Cluster 10: epoch = 00100, train loss = 1.433690, test loss = 1.453420.\n",
      "Cluster 10: epoch = 00110, train loss = 1.375706, test loss = 1.400409.\n",
      "Cluster 10: epoch = 00120, train loss = 1.320690, test loss = 1.350416.\n",
      "Cluster 10: epoch = 00130, train loss = 1.268818, test loss = 1.303599.\n",
      "Cluster 10: epoch = 00140, train loss = 1.220188, test loss = 1.260042.\n",
      "Cluster 10: epoch = 00150, train loss = 1.174822, test loss = 1.219756.\n",
      "Cluster 10: epoch = 00160, train loss = 1.132675, test loss = 1.182688.\n",
      "Cluster 10: epoch = 00170, train loss = 1.093665, test loss = 1.148747.\n",
      "Cluster 10: epoch = 00180, train loss = 1.057674, test loss = 1.117813.\n",
      "Cluster 10: epoch = 00190, train loss = 1.024549, test loss = 1.089731.\n",
      "Cluster 10: epoch = 00200, train loss = 0.994123, test loss = 1.064330.\n",
      "Cluster 10: epoch = 00210, train loss = 0.966211, test loss = 1.041423.\n",
      "Cluster 10: epoch = 00220, train loss = 0.940630, test loss = 1.020826.\n",
      "Cluster 10: epoch = 00230, train loss = 0.917193, test loss = 1.002354.\n",
      "Cluster 10: epoch = 00240, train loss = 0.895729, test loss = 0.985833.\n",
      "Cluster 10: epoch = 00250, train loss = 0.876053, test loss = 0.971077.\n",
      "Cluster 10: epoch = 00260, train loss = 0.857993, test loss = 0.957918.\n",
      "Cluster 10: epoch = 00270, train loss = 0.841382, test loss = 0.946189.\n",
      "Cluster 10: epoch = 00280, train loss = 0.826075, test loss = 0.935740.\n",
      "Cluster 10: epoch = 00290, train loss = 0.811929, test loss = 0.926436.\n",
      "Cluster 10: epoch = 00300, train loss = 0.798813, test loss = 0.918138.\n",
      "Cluster 10: epoch = 00310, train loss = 0.786611, test loss = 0.910733.\n",
      "Cluster 10: epoch = 00320, train loss = 0.775208, test loss = 0.904105.\n",
      "Cluster 10: epoch = 00330, train loss = 0.764510, test loss = 0.898162.\n",
      "Cluster 10: epoch = 00340, train loss = 0.754432, test loss = 0.892818.\n",
      "Cluster 10: epoch = 00350, train loss = 0.744892, test loss = 0.887993.\n",
      "Cluster 10: epoch = 00360, train loss = 0.735822, test loss = 0.883618.\n",
      "Cluster 10: epoch = 00370, train loss = 0.727165, test loss = 0.879634.\n",
      "Cluster 10: epoch = 00380, train loss = 0.718866, test loss = 0.875988.\n",
      "Cluster 10: epoch = 00390, train loss = 0.710874, test loss = 0.872626.\n",
      "Cluster 10: epoch = 00400, train loss = 0.703151, test loss = 0.869510.\n",
      "Cluster 10: epoch = 00410, train loss = 0.695662, test loss = 0.866608.\n",
      "Cluster 10: epoch = 00420, train loss = 0.688381, test loss = 0.863896.\n",
      "Cluster 10: epoch = 00430, train loss = 0.681277, test loss = 0.861331.\n",
      "Cluster 10: epoch = 00440, train loss = 0.674330, test loss = 0.858894.\n",
      "Cluster 10: epoch = 00450, train loss = 0.667521, test loss = 0.856574.\n",
      "Cluster 10: epoch = 00460, train loss = 0.660833, test loss = 0.854346.\n",
      "Cluster 10: epoch = 00470, train loss = 0.654253, test loss = 0.852207.\n",
      "Cluster 10: epoch = 00480, train loss = 0.647772, test loss = 0.850135.\n",
      "Cluster 10: epoch = 00490, train loss = 0.641378, test loss = 0.848124.\n",
      "Cluster 10: epoch = 00500, train loss = 0.635063, test loss = 0.846164.\n",
      "Cluster 10: epoch = 00510, train loss = 0.628822, test loss = 0.844249.\n",
      "Cluster 10: epoch = 00520, train loss = 0.622648, test loss = 0.842369.\n",
      "Cluster 10: epoch = 00530, train loss = 0.616539, test loss = 0.840527.\n",
      "Cluster 10: epoch = 00540, train loss = 0.610491, test loss = 0.838718.\n",
      "Cluster 10: epoch = 00550, train loss = 0.604499, test loss = 0.836931.\n",
      "Cluster 10: epoch = 00560, train loss = 0.598562, test loss = 0.835171.\n",
      "Cluster 10: epoch = 00570, train loss = 0.592679, test loss = 0.833437.\n",
      "Cluster 10: epoch = 00580, train loss = 0.586849, test loss = 0.831725.\n",
      "Cluster 10: epoch = 00590, train loss = 0.581069, test loss = 0.830035.\n",
      "Cluster 10: epoch = 00600, train loss = 0.575341, test loss = 0.828363.\n",
      "Cluster 10: epoch = 00610, train loss = 0.569663, test loss = 0.826708.\n",
      "Cluster 10: epoch = 00620, train loss = 0.564035, test loss = 0.825062.\n",
      "Cluster 10: epoch = 00630, train loss = 0.558455, test loss = 0.823434.\n",
      "Cluster 10: epoch = 00640, train loss = 0.552924, test loss = 0.821818.\n",
      "Cluster 10: epoch = 00650, train loss = 0.547442, test loss = 0.820220.\n",
      "Cluster 10: epoch = 00660, train loss = 0.542010, test loss = 0.818636.\n",
      "Cluster 10: epoch = 00670, train loss = 0.536627, test loss = 0.817069.\n",
      "Cluster 10: epoch = 00680, train loss = 0.531292, test loss = 0.815519.\n",
      "Cluster 10: epoch = 00690, train loss = 0.526005, test loss = 0.813980.\n",
      "Cluster 10: epoch = 00700, train loss = 0.520767, test loss = 0.812456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 10 done in 0:00:01.304359.\n",
      "Writing the output model to \"./regularized_synonym_phi.k10.trained\".\n",
      "./regularized_synonym_phi.k11.trained\n",
      "Cluster 11: 132 train items and 33 test items available; using 1 steps of 132 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cluster 11: epoch = 00001, train loss = 1.871584, test loss = 1.855018.\n",
      "Cluster 11: epoch = 00010, train loss = 1.822252, test loss = 1.806706.\n",
      "Cluster 11: epoch = 00020, train loss = 1.741368, test loss = 1.727609.\n",
      "Cluster 11: epoch = 00030, train loss = 1.650176, test loss = 1.638650.\n",
      "Cluster 11: epoch = 00040, train loss = 1.557750, test loss = 1.548805.\n",
      "Cluster 11: epoch = 00050, train loss = 1.469596, test loss = 1.463520.\n",
      "Cluster 11: epoch = 00060, train loss = 1.388890, test loss = 1.385930.\n",
      "Cluster 11: epoch = 00070, train loss = 1.317151, test loss = 1.317523.\n",
      "Cluster 11: epoch = 00080, train loss = 1.254761, test loss = 1.258642.\n",
      "Cluster 11: epoch = 00090, train loss = 1.201328, test loss = 1.208883.\n",
      "Cluster 11: epoch = 00100, train loss = 1.156023, test loss = 1.167382.\n",
      "Cluster 11: epoch = 00110, train loss = 1.117782, test loss = 1.133060.\n",
      "Cluster 11: epoch = 00120, train loss = 1.085481, test loss = 1.104778.\n",
      "Cluster 11: epoch = 00130, train loss = 1.058029, test loss = 1.081426.\n",
      "Cluster 11: epoch = 00140, train loss = 1.034439, test loss = 1.062002.\n",
      "Cluster 11: epoch = 00150, train loss = 1.013859, test loss = 1.045643.\n",
      "Cluster 11: epoch = 00160, train loss = 0.995582, test loss = 1.031635.\n",
      "Cluster 11: epoch = 00170, train loss = 0.979037, test loss = 1.019398.\n",
      "Cluster 11: epoch = 00180, train loss = 0.963781, test loss = 1.008479.\n",
      "Cluster 11: epoch = 00190, train loss = 0.949479, test loss = 0.998538.\n",
      "Cluster 11: epoch = 00200, train loss = 0.935885, test loss = 0.989320.\n",
      "Cluster 11: epoch = 00210, train loss = 0.922816, test loss = 0.980640.\n",
      "Cluster 11: epoch = 00220, train loss = 0.910148, test loss = 0.972368.\n",
      "Cluster 11: epoch = 00230, train loss = 0.897796, test loss = 0.964414.\n",
      "Cluster 11: epoch = 00240, train loss = 0.885701, test loss = 0.956715.\n",
      "Cluster 11: epoch = 00250, train loss = 0.873827, test loss = 0.949232.\n",
      "Cluster 11: epoch = 00260, train loss = 0.862151, test loss = 0.941941.\n",
      "Cluster 11: epoch = 00270, train loss = 0.850660, test loss = 0.934820.\n",
      "Cluster 11: epoch = 00280, train loss = 0.839346, test loss = 0.927855.\n",
      "Cluster 11: epoch = 00290, train loss = 0.828203, test loss = 0.921040.\n",
      "Cluster 11: epoch = 00300, train loss = 0.817233, test loss = 0.914375.\n",
      "Cluster 11: epoch = 00310, train loss = 0.806434, test loss = 0.907857.\n",
      "Cluster 11: epoch = 00320, train loss = 0.795806, test loss = 0.901477.\n",
      "Cluster 11: epoch = 00330, train loss = 0.785350, test loss = 0.895237.\n",
      "Cluster 11: epoch = 00340, train loss = 0.775067, test loss = 0.889139.\n",
      "Cluster 11: epoch = 00350, train loss = 0.764958, test loss = 0.883183.\n",
      "Cluster 11: epoch = 00360, train loss = 0.755019, test loss = 0.877364.\n",
      "Cluster 11: epoch = 00370, train loss = 0.745253, test loss = 0.871677.\n",
      "Cluster 11: epoch = 00380, train loss = 0.735656, test loss = 0.866121.\n",
      "Cluster 11: epoch = 00390, train loss = 0.726228, test loss = 0.860695.\n",
      "Cluster 11: epoch = 00400, train loss = 0.716967, test loss = 0.855397.\n",
      "Cluster 11: epoch = 00410, train loss = 0.707872, test loss = 0.850228.\n",
      "Cluster 11: epoch = 00420, train loss = 0.698940, test loss = 0.845185.\n",
      "Cluster 11: epoch = 00430, train loss = 0.690169, test loss = 0.840259.\n",
      "Cluster 11: epoch = 00440, train loss = 0.681556, test loss = 0.835449.\n",
      "Cluster 11: epoch = 00450, train loss = 0.673100, test loss = 0.830757.\n",
      "Cluster 11: epoch = 00460, train loss = 0.664798, test loss = 0.826177.\n",
      "Cluster 11: epoch = 00470, train loss = 0.656645, test loss = 0.821705.\n",
      "Cluster 11: epoch = 00480, train loss = 0.648640, test loss = 0.817342.\n",
      "Cluster 11: epoch = 00490, train loss = 0.640781, test loss = 0.813080.\n",
      "Cluster 11: epoch = 00500, train loss = 0.633063, test loss = 0.808914.\n",
      "Cluster 11: epoch = 00510, train loss = 0.625483, test loss = 0.804849.\n",
      "Cluster 11: epoch = 00520, train loss = 0.618040, test loss = 0.800881.\n",
      "Cluster 11: epoch = 00530, train loss = 0.610731, test loss = 0.797008.\n",
      "Cluster 11: epoch = 00540, train loss = 0.603551, test loss = 0.793224.\n",
      "Cluster 11: epoch = 00550, train loss = 0.596499, test loss = 0.789526.\n",
      "Cluster 11: epoch = 00560, train loss = 0.589572, test loss = 0.785910.\n",
      "Cluster 11: epoch = 00570, train loss = 0.582765, test loss = 0.782375.\n",
      "Cluster 11: epoch = 00580, train loss = 0.576079, test loss = 0.778922.\n",
      "Cluster 11: epoch = 00590, train loss = 0.569509, test loss = 0.775545.\n",
      "Cluster 11: epoch = 00600, train loss = 0.563054, test loss = 0.772244.\n",
      "Cluster 11: epoch = 00610, train loss = 0.556709, test loss = 0.769015.\n",
      "Cluster 11: epoch = 00620, train loss = 0.550473, test loss = 0.765857.\n",
      "Cluster 11: epoch = 00630, train loss = 0.544343, test loss = 0.762770.\n",
      "Cluster 11: epoch = 00640, train loss = 0.538318, test loss = 0.759744.\n",
      "Cluster 11: epoch = 00650, train loss = 0.532394, test loss = 0.756781.\n",
      "Cluster 11: epoch = 00660, train loss = 0.526569, test loss = 0.753887.\n",
      "Cluster 11: epoch = 00670, train loss = 0.520842, test loss = 0.751054.\n",
      "Cluster 11: epoch = 00680, train loss = 0.515210, test loss = 0.748280.\n",
      "Cluster 11: epoch = 00690, train loss = 0.509670, test loss = 0.745564.\n",
      "Cluster 11: epoch = 00700, train loss = 0.504221, test loss = 0.742901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 11 done in 0:00:01.751879.\n",
      "Writing the output model to \"./regularized_synonym_phi.k11.trained\".\n",
      "./regularized_synonym_phi.k12.trained\n",
      "Cluster 12: 176 train items and 49 test items available; using 1 steps of 176 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cluster 12: epoch = 00001, train loss = 1.872602, test loss = 1.866671.\n",
      "Cluster 12: epoch = 00010, train loss = 1.792192, test loss = 1.785835.\n",
      "Cluster 12: epoch = 00020, train loss = 1.665439, test loss = 1.658633.\n",
      "Cluster 12: epoch = 00030, train loss = 1.528872, test loss = 1.521940.\n",
      "Cluster 12: epoch = 00040, train loss = 1.397489, test loss = 1.390911.\n",
      "Cluster 12: epoch = 00050, train loss = 1.279390, test loss = 1.273717.\n",
      "Cluster 12: epoch = 00060, train loss = 1.178190, test loss = 1.173970.\n",
      "Cluster 12: epoch = 00070, train loss = 1.094505, test loss = 1.092240.\n",
      "Cluster 12: epoch = 00080, train loss = 1.027115, test loss = 1.027234.\n",
      "Cluster 12: epoch = 00090, train loss = 0.973848, test loss = 0.976699.\n",
      "Cluster 12: epoch = 00100, train loss = 0.932175, test loss = 0.938026.\n",
      "Cluster 12: epoch = 00110, train loss = 0.899612, test loss = 0.908658.\n",
      "Cluster 12: epoch = 00120, train loss = 0.873939, test loss = 0.886317.\n",
      "Cluster 12: epoch = 00130, train loss = 0.853306, test loss = 0.869106.\n",
      "Cluster 12: epoch = 00140, train loss = 0.836255, test loss = 0.855527.\n",
      "Cluster 12: epoch = 00150, train loss = 0.821682, test loss = 0.844453.\n",
      "Cluster 12: epoch = 00160, train loss = 0.808784, test loss = 0.835067.\n",
      "Cluster 12: epoch = 00170, train loss = 0.797001, test loss = 0.826791.\n",
      "Cluster 12: epoch = 00180, train loss = 0.785949, test loss = 0.819237.\n",
      "Cluster 12: epoch = 00190, train loss = 0.775380, test loss = 0.812151.\n",
      "Cluster 12: epoch = 00200, train loss = 0.765134, test loss = 0.805371.\n",
      "Cluster 12: epoch = 00210, train loss = 0.755116, test loss = 0.798796.\n",
      "Cluster 12: epoch = 00220, train loss = 0.745267, test loss = 0.792372.\n",
      "Cluster 12: epoch = 00230, train loss = 0.735557, test loss = 0.786066.\n",
      "Cluster 12: epoch = 00240, train loss = 0.725970, test loss = 0.779856.\n",
      "Cluster 12: epoch = 00250, train loss = 0.716500, test loss = 0.773738.\n",
      "Cluster 12: epoch = 00260, train loss = 0.707147, test loss = 0.767710.\n",
      "Cluster 12: epoch = 00270, train loss = 0.697910, test loss = 0.761768.\n",
      "Cluster 12: epoch = 00280, train loss = 0.688791, test loss = 0.755918.\n",
      "Cluster 12: epoch = 00290, train loss = 0.679794, test loss = 0.750162.\n",
      "Cluster 12: epoch = 00300, train loss = 0.670922, test loss = 0.744502.\n",
      "Cluster 12: epoch = 00310, train loss = 0.662177, test loss = 0.738937.\n",
      "Cluster 12: epoch = 00320, train loss = 0.653560, test loss = 0.733466.\n",
      "Cluster 12: epoch = 00330, train loss = 0.645074, test loss = 0.728093.\n",
      "Cluster 12: epoch = 00340, train loss = 0.636717, test loss = 0.722816.\n",
      "Cluster 12: epoch = 00350, train loss = 0.628492, test loss = 0.717633.\n",
      "Cluster 12: epoch = 00360, train loss = 0.620397, test loss = 0.712543.\n",
      "Cluster 12: epoch = 00370, train loss = 0.612434, test loss = 0.707551.\n",
      "Cluster 12: epoch = 00380, train loss = 0.604602, test loss = 0.702654.\n",
      "Cluster 12: epoch = 00390, train loss = 0.596898, test loss = 0.697849.\n",
      "Cluster 12: epoch = 00400, train loss = 0.589323, test loss = 0.693134.\n",
      "Cluster 12: epoch = 00410, train loss = 0.581875, test loss = 0.688509.\n",
      "Cluster 12: epoch = 00420, train loss = 0.574554, test loss = 0.683971.\n",
      "Cluster 12: epoch = 00430, train loss = 0.567356, test loss = 0.679515.\n",
      "Cluster 12: epoch = 00440, train loss = 0.560281, test loss = 0.675148.\n",
      "Cluster 12: epoch = 00450, train loss = 0.553327, test loss = 0.670863.\n",
      "Cluster 12: epoch = 00460, train loss = 0.546490, test loss = 0.666659.\n",
      "Cluster 12: epoch = 00470, train loss = 0.539770, test loss = 0.662532.\n",
      "Cluster 12: epoch = 00480, train loss = 0.533165, test loss = 0.658481.\n",
      "Cluster 12: epoch = 00490, train loss = 0.526672, test loss = 0.654504.\n",
      "Cluster 12: epoch = 00500, train loss = 0.520291, test loss = 0.650600.\n",
      "Cluster 12: epoch = 00510, train loss = 0.514017, test loss = 0.646771.\n",
      "Cluster 12: epoch = 00520, train loss = 0.507850, test loss = 0.643013.\n",
      "Cluster 12: epoch = 00530, train loss = 0.501786, test loss = 0.639320.\n",
      "Cluster 12: epoch = 00540, train loss = 0.495825, test loss = 0.635690.\n",
      "Cluster 12: epoch = 00550, train loss = 0.489964, test loss = 0.632124.\n",
      "Cluster 12: epoch = 00560, train loss = 0.484202, test loss = 0.628624.\n",
      "Cluster 12: epoch = 00570, train loss = 0.478536, test loss = 0.625186.\n",
      "Cluster 12: epoch = 00580, train loss = 0.472964, test loss = 0.621803.\n",
      "Cluster 12: epoch = 00590, train loss = 0.467484, test loss = 0.618479.\n",
      "Cluster 12: epoch = 00600, train loss = 0.462094, test loss = 0.615215.\n",
      "Cluster 12: epoch = 00610, train loss = 0.456793, test loss = 0.612004.\n",
      "Cluster 12: epoch = 00620, train loss = 0.451578, test loss = 0.608845.\n",
      "Cluster 12: epoch = 00630, train loss = 0.446448, test loss = 0.605738.\n",
      "Cluster 12: epoch = 00640, train loss = 0.441402, test loss = 0.602680.\n",
      "Cluster 12: epoch = 00650, train loss = 0.436436, test loss = 0.599671.\n",
      "Cluster 12: epoch = 00660, train loss = 0.431551, test loss = 0.596712.\n",
      "Cluster 12: epoch = 00670, train loss = 0.426743, test loss = 0.593799.\n",
      "Cluster 12: epoch = 00680, train loss = 0.422012, test loss = 0.590931.\n",
      "Cluster 12: epoch = 00690, train loss = 0.417357, test loss = 0.588108.\n",
      "Cluster 12: epoch = 00700, train loss = 0.412774, test loss = 0.585330.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 12 done in 0:00:01.956166.\n",
      "Writing the output model to \"./regularized_synonym_phi.k12.trained\".\n",
      "./regularized_synonym_phi.k13.trained\n",
      "Cluster 13: 374 train items and 121 test items available; using 1 steps of 374 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cluster 13: epoch = 00001, train loss = 1.880945, test loss = 1.850832.\n",
      "Cluster 13: epoch = 00010, train loss = 1.782003, test loss = 1.753574.\n",
      "Cluster 13: epoch = 00020, train loss = 1.639715, test loss = 1.614312.\n",
      "Cluster 13: epoch = 00030, train loss = 1.502839, test loss = 1.481365.\n",
      "Cluster 13: epoch = 00040, train loss = 1.387486, test loss = 1.370689.\n",
      "Cluster 13: epoch = 00050, train loss = 1.297801, test loss = 1.286256.\n",
      "Cluster 13: epoch = 00060, train loss = 1.231262, test loss = 1.225377.\n",
      "Cluster 13: epoch = 00070, train loss = 1.182533, test loss = 1.182563.\n",
      "Cluster 13: epoch = 00080, train loss = 1.146010, test loss = 1.152090.\n",
      "Cluster 13: epoch = 00090, train loss = 1.117107, test loss = 1.129281.\n",
      "Cluster 13: epoch = 00100, train loss = 1.092611, test loss = 1.110869.\n",
      "Cluster 13: epoch = 00110, train loss = 1.070523, test loss = 1.094828.\n",
      "Cluster 13: epoch = 00120, train loss = 1.049729, test loss = 1.080030.\n",
      "Cluster 13: epoch = 00130, train loss = 1.029667, test loss = 1.065901.\n",
      "Cluster 13: epoch = 00140, train loss = 1.010084, test loss = 1.052189.\n",
      "Cluster 13: epoch = 00150, train loss = 0.990887, test loss = 1.038792.\n",
      "Cluster 13: epoch = 00160, train loss = 0.972058, test loss = 1.025686.\n",
      "Cluster 13: epoch = 00170, train loss = 0.953602, test loss = 1.012878.\n",
      "Cluster 13: epoch = 00180, train loss = 0.935537, test loss = 1.000376.\n",
      "Cluster 13: epoch = 00190, train loss = 0.917877, test loss = 0.988195.\n",
      "Cluster 13: epoch = 00200, train loss = 0.900638, test loss = 0.976343.\n",
      "Cluster 13: epoch = 00210, train loss = 0.883825, test loss = 0.964827.\n",
      "Cluster 13: epoch = 00220, train loss = 0.867447, test loss = 0.953646.\n",
      "Cluster 13: epoch = 00230, train loss = 0.851505, test loss = 0.942791.\n",
      "Cluster 13: epoch = 00240, train loss = 0.835995, test loss = 0.932263.\n",
      "Cluster 13: epoch = 00250, train loss = 0.820916, test loss = 0.922060.\n",
      "Cluster 13: epoch = 00260, train loss = 0.806261, test loss = 0.912175.\n",
      "Cluster 13: epoch = 00270, train loss = 0.792021, test loss = 0.902600.\n",
      "Cluster 13: epoch = 00280, train loss = 0.778190, test loss = 0.893321.\n",
      "Cluster 13: epoch = 00290, train loss = 0.764757, test loss = 0.884333.\n",
      "Cluster 13: epoch = 00300, train loss = 0.751712, test loss = 0.875626.\n",
      "Cluster 13: epoch = 00310, train loss = 0.739044, test loss = 0.867192.\n",
      "Cluster 13: epoch = 00320, train loss = 0.726740, test loss = 0.859021.\n",
      "Cluster 13: epoch = 00330, train loss = 0.714791, test loss = 0.851095.\n",
      "Cluster 13: epoch = 00340, train loss = 0.703186, test loss = 0.843411.\n",
      "Cluster 13: epoch = 00350, train loss = 0.691912, test loss = 0.835951.\n",
      "Cluster 13: epoch = 00360, train loss = 0.680960, test loss = 0.828720.\n",
      "Cluster 13: epoch = 00370, train loss = 0.670317, test loss = 0.821708.\n",
      "Cluster 13: epoch = 00380, train loss = 0.659974, test loss = 0.814900.\n",
      "Cluster 13: epoch = 00390, train loss = 0.649920, test loss = 0.808291.\n",
      "Cluster 13: epoch = 00400, train loss = 0.640145, test loss = 0.801867.\n",
      "Cluster 13: epoch = 00410, train loss = 0.630640, test loss = 0.795621.\n",
      "Cluster 13: epoch = 00420, train loss = 0.621394, test loss = 0.789551.\n",
      "Cluster 13: epoch = 00430, train loss = 0.612400, test loss = 0.783649.\n",
      "Cluster 13: epoch = 00440, train loss = 0.603648, test loss = 0.777906.\n",
      "Cluster 13: epoch = 00450, train loss = 0.595130, test loss = 0.772316.\n",
      "Cluster 13: epoch = 00460, train loss = 0.586838, test loss = 0.766876.\n",
      "Cluster 13: epoch = 00470, train loss = 0.578764, test loss = 0.761572.\n",
      "Cluster 13: epoch = 00480, train loss = 0.570900, test loss = 0.756399.\n",
      "Cluster 13: epoch = 00490, train loss = 0.563241, test loss = 0.751364.\n",
      "Cluster 13: epoch = 00500, train loss = 0.555777, test loss = 0.746460.\n",
      "Cluster 13: epoch = 00510, train loss = 0.548504, test loss = 0.741672.\n",
      "Cluster 13: epoch = 00520, train loss = 0.541414, test loss = 0.737004.\n",
      "Cluster 13: epoch = 00530, train loss = 0.534502, test loss = 0.732451.\n",
      "Cluster 13: epoch = 00540, train loss = 0.527762, test loss = 0.727998.\n",
      "Cluster 13: epoch = 00550, train loss = 0.521188, test loss = 0.723652.\n",
      "Cluster 13: epoch = 00560, train loss = 0.514774, test loss = 0.719408.\n",
      "Cluster 13: epoch = 00570, train loss = 0.508517, test loss = 0.715264.\n",
      "Cluster 13: epoch = 00580, train loss = 0.502410, test loss = 0.711205.\n",
      "Cluster 13: epoch = 00590, train loss = 0.496450, test loss = 0.707240.\n",
      "Cluster 13: epoch = 00600, train loss = 0.490630, test loss = 0.703364.\n",
      "Cluster 13: epoch = 00610, train loss = 0.484947, test loss = 0.699573.\n",
      "Cluster 13: epoch = 00620, train loss = 0.479397, test loss = 0.695861.\n",
      "Cluster 13: epoch = 00630, train loss = 0.473975, test loss = 0.692227.\n",
      "Cluster 13: epoch = 00640, train loss = 0.468678, test loss = 0.688675.\n",
      "Cluster 13: epoch = 00650, train loss = 0.463501, test loss = 0.685199.\n",
      "Cluster 13: epoch = 00660, train loss = 0.458442, test loss = 0.681792.\n",
      "Cluster 13: epoch = 00670, train loss = 0.453496, test loss = 0.678450.\n",
      "Cluster 13: epoch = 00680, train loss = 0.448661, test loss = 0.675171.\n",
      "Cluster 13: epoch = 00690, train loss = 0.443931, test loss = 0.671959.\n",
      "Cluster 13: epoch = 00700, train loss = 0.439307, test loss = 0.668806.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 13 done in 0:00:03.293062.\n",
      "Writing the output model to \"./regularized_synonym_phi.k13.trained\".\n",
      "./regularized_synonym_phi.k14.trained\n",
      "Cluster 14: 137 train items and 51 test items available; using 1 steps of 137 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cluster 14: epoch = 00001, train loss = 1.881047, test loss = 1.846004.\n",
      "Cluster 14: epoch = 00010, train loss = 1.830318, test loss = 1.798528.\n",
      "Cluster 14: epoch = 00020, train loss = 1.747330, test loss = 1.721306.\n",
      "Cluster 14: epoch = 00030, train loss = 1.653620, test loss = 1.634825.\n",
      "Cluster 14: epoch = 00040, train loss = 1.558223, test loss = 1.547728.\n",
      "Cluster 14: epoch = 00050, train loss = 1.466613, test loss = 1.465212.\n",
      "Cluster 14: epoch = 00060, train loss = 1.381972, test loss = 1.390240.\n",
      "Cluster 14: epoch = 00070, train loss = 1.305904, test loss = 1.324222.\n",
      "Cluster 14: epoch = 00080, train loss = 1.238898, test loss = 1.267485.\n",
      "Cluster 14: epoch = 00090, train loss = 1.180695, test loss = 1.219631.\n",
      "Cluster 14: epoch = 00100, train loss = 1.130592, test loss = 1.179844.\n",
      "Cluster 14: epoch = 00110, train loss = 1.087643, test loss = 1.147084.\n",
      "Cluster 14: epoch = 00120, train loss = 1.050815, test loss = 1.120248.\n",
      "Cluster 14: epoch = 00130, train loss = 1.019087, test loss = 1.098266.\n",
      "Cluster 14: epoch = 00140, train loss = 0.991523, test loss = 1.080156.\n",
      "Cluster 14: epoch = 00150, train loss = 0.967288, test loss = 1.065062.\n",
      "Cluster 14: epoch = 00160, train loss = 0.945676, test loss = 1.052270.\n",
      "Cluster 14: epoch = 00170, train loss = 0.926119, test loss = 1.041208.\n",
      "Cluster 14: epoch = 00180, train loss = 0.908153, test loss = 1.031426.\n",
      "Cluster 14: epoch = 00190, train loss = 0.891422, test loss = 1.022578.\n",
      "Cluster 14: epoch = 00200, train loss = 0.875651, test loss = 1.014413.\n",
      "Cluster 14: epoch = 00210, train loss = 0.860640, test loss = 1.006734.\n",
      "Cluster 14: epoch = 00220, train loss = 0.846240, test loss = 0.999416.\n",
      "Cluster 14: epoch = 00230, train loss = 0.832343, test loss = 0.992368.\n",
      "Cluster 14: epoch = 00240, train loss = 0.818872, test loss = 0.985532.\n",
      "Cluster 14: epoch = 00250, train loss = 0.805774, test loss = 0.978869.\n",
      "Cluster 14: epoch = 00260, train loss = 0.793011, test loss = 0.972367.\n",
      "Cluster 14: epoch = 00270, train loss = 0.780562, test loss = 0.966009.\n",
      "Cluster 14: epoch = 00280, train loss = 0.768402, test loss = 0.959794.\n",
      "Cluster 14: epoch = 00290, train loss = 0.756520, test loss = 0.953710.\n",
      "Cluster 14: epoch = 00300, train loss = 0.744908, test loss = 0.947754.\n",
      "Cluster 14: epoch = 00310, train loss = 0.733556, test loss = 0.941918.\n",
      "Cluster 14: epoch = 00320, train loss = 0.722458, test loss = 0.936220.\n",
      "Cluster 14: epoch = 00330, train loss = 0.711609, test loss = 0.930660.\n",
      "Cluster 14: epoch = 00340, train loss = 0.701001, test loss = 0.925233.\n",
      "Cluster 14: epoch = 00350, train loss = 0.690629, test loss = 0.919939.\n",
      "Cluster 14: epoch = 00360, train loss = 0.680487, test loss = 0.914767.\n",
      "Cluster 14: epoch = 00370, train loss = 0.670570, test loss = 0.909727.\n",
      "Cluster 14: epoch = 00380, train loss = 0.660873, test loss = 0.904815.\n",
      "Cluster 14: epoch = 00390, train loss = 0.651390, test loss = 0.900019.\n",
      "Cluster 14: epoch = 00400, train loss = 0.642118, test loss = 0.895339.\n",
      "Cluster 14: epoch = 00410, train loss = 0.633047, test loss = 0.890778.\n",
      "Cluster 14: epoch = 00420, train loss = 0.624174, test loss = 0.886330.\n",
      "Cluster 14: epoch = 00430, train loss = 0.615492, test loss = 0.881986.\n",
      "Cluster 14: epoch = 00440, train loss = 0.606997, test loss = 0.877749.\n",
      "Cluster 14: epoch = 00450, train loss = 0.598684, test loss = 0.873614.\n",
      "Cluster 14: epoch = 00460, train loss = 0.590547, test loss = 0.869579.\n",
      "Cluster 14: epoch = 00470, train loss = 0.582583, test loss = 0.865633.\n",
      "Cluster 14: epoch = 00480, train loss = 0.574786, test loss = 0.861785.\n",
      "Cluster 14: epoch = 00490, train loss = 0.567150, test loss = 0.858034.\n",
      "Cluster 14: epoch = 00500, train loss = 0.559672, test loss = 0.854369.\n",
      "Cluster 14: epoch = 00510, train loss = 0.552345, test loss = 0.850784.\n",
      "Cluster 14: epoch = 00520, train loss = 0.545169, test loss = 0.847278.\n",
      "Cluster 14: epoch = 00530, train loss = 0.538137, test loss = 0.843852.\n",
      "Cluster 14: epoch = 00540, train loss = 0.531247, test loss = 0.840497.\n",
      "Cluster 14: epoch = 00550, train loss = 0.524494, test loss = 0.837210.\n",
      "Cluster 14: epoch = 00560, train loss = 0.517877, test loss = 0.834001.\n",
      "Cluster 14: epoch = 00570, train loss = 0.511389, test loss = 0.830866.\n",
      "Cluster 14: epoch = 00580, train loss = 0.505029, test loss = 0.827800.\n",
      "Cluster 14: epoch = 00590, train loss = 0.498791, test loss = 0.824786.\n",
      "Cluster 14: epoch = 00600, train loss = 0.492676, test loss = 0.821843.\n",
      "Cluster 14: epoch = 00610, train loss = 0.486677, test loss = 0.818971.\n",
      "Cluster 14: epoch = 00620, train loss = 0.480792, test loss = 0.816150.\n",
      "Cluster 14: epoch = 00630, train loss = 0.475019, test loss = 0.813381.\n",
      "Cluster 14: epoch = 00640, train loss = 0.469356, test loss = 0.810655.\n",
      "Cluster 14: epoch = 00650, train loss = 0.463800, test loss = 0.807991.\n",
      "Cluster 14: epoch = 00660, train loss = 0.458347, test loss = 0.805381.\n",
      "Cluster 14: epoch = 00670, train loss = 0.452998, test loss = 0.802817.\n",
      "Cluster 14: epoch = 00680, train loss = 0.447747, test loss = 0.800306.\n",
      "Cluster 14: epoch = 00690, train loss = 0.442592, test loss = 0.797841.\n",
      "Cluster 14: epoch = 00700, train loss = 0.437532, test loss = 0.795418.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 14 done in 0:00:01.770439.\n",
      "Writing the output model to \"./regularized_synonym_phi.k14.trained\".\n",
      "./regularized_synonym_phi.k15.trained\n",
      "Cluster 15: 134 train items and 31 test items available; using 1 steps of 134 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cluster 15: epoch = 00001, train loss = 1.823682, test loss = 1.831050.\n",
      "Cluster 15: epoch = 00010, train loss = 1.765856, test loss = 1.774990.\n",
      "Cluster 15: epoch = 00020, train loss = 1.672081, test loss = 1.684241.\n",
      "Cluster 15: epoch = 00030, train loss = 1.567883, test loss = 1.583658.\n",
      "Cluster 15: epoch = 00040, train loss = 1.464158, test loss = 1.483860.\n",
      "Cluster 15: epoch = 00050, train loss = 1.367304, test loss = 1.391085.\n",
      "Cluster 15: epoch = 00060, train loss = 1.280768, test loss = 1.308669.\n",
      "Cluster 15: epoch = 00070, train loss = 1.205922, test loss = 1.237925.\n",
      "Cluster 15: epoch = 00080, train loss = 1.142734, test loss = 1.178789.\n",
      "Cluster 15: epoch = 00090, train loss = 1.090324, test loss = 1.130358.\n",
      "Cluster 15: epoch = 00100, train loss = 1.047339, test loss = 1.091282.\n",
      "Cluster 15: epoch = 00110, train loss = 1.012254, test loss = 1.060041.\n",
      "Cluster 15: epoch = 00120, train loss = 0.983557, test loss = 1.035131.\n",
      "Cluster 15: epoch = 00130, train loss = 0.959873, test loss = 1.015186.\n",
      "Cluster 15: epoch = 00140, train loss = 0.940009, test loss = 0.999020.\n",
      "Cluster 15: epoch = 00150, train loss = 0.922988, test loss = 0.985662.\n",
      "Cluster 15: epoch = 00160, train loss = 0.908033, test loss = 0.974347.\n",
      "Cluster 15: epoch = 00170, train loss = 0.894550, test loss = 0.964487.\n",
      "Cluster 15: epoch = 00180, train loss = 0.882099, test loss = 0.955642.\n",
      "Cluster 15: epoch = 00190, train loss = 0.870365, test loss = 0.947501.\n",
      "Cluster 15: epoch = 00200, train loss = 0.859124, test loss = 0.939847.\n",
      "Cluster 15: epoch = 00210, train loss = 0.848225, test loss = 0.932525.\n",
      "Cluster 15: epoch = 00220, train loss = 0.837567, test loss = 0.925437.\n",
      "Cluster 15: epoch = 00230, train loss = 0.827086, test loss = 0.918518.\n",
      "Cluster 15: epoch = 00240, train loss = 0.816747, test loss = 0.911727.\n",
      "Cluster 15: epoch = 00250, train loss = 0.806524, test loss = 0.905043.\n",
      "Cluster 15: epoch = 00260, train loss = 0.796408, test loss = 0.898454.\n",
      "Cluster 15: epoch = 00270, train loss = 0.786394, test loss = 0.891948.\n",
      "Cluster 15: epoch = 00280, train loss = 0.776482, test loss = 0.885527.\n",
      "Cluster 15: epoch = 00290, train loss = 0.766674, test loss = 0.879198.\n",
      "Cluster 15: epoch = 00300, train loss = 0.756973, test loss = 0.872959.\n",
      "Cluster 15: epoch = 00310, train loss = 0.747382, test loss = 0.866812.\n",
      "Cluster 15: epoch = 00320, train loss = 0.737907, test loss = 0.860757.\n",
      "Cluster 15: epoch = 00330, train loss = 0.728548, test loss = 0.854797.\n",
      "Cluster 15: epoch = 00340, train loss = 0.719310, test loss = 0.848931.\n",
      "Cluster 15: epoch = 00350, train loss = 0.710196, test loss = 0.843163.\n",
      "Cluster 15: epoch = 00360, train loss = 0.701207, test loss = 0.837490.\n",
      "Cluster 15: epoch = 00370, train loss = 0.692346, test loss = 0.831916.\n",
      "Cluster 15: epoch = 00380, train loss = 0.683613, test loss = 0.826439.\n",
      "Cluster 15: epoch = 00390, train loss = 0.675011, test loss = 0.821057.\n",
      "Cluster 15: epoch = 00400, train loss = 0.666539, test loss = 0.815772.\n",
      "Cluster 15: epoch = 00410, train loss = 0.658197, test loss = 0.810585.\n",
      "Cluster 15: epoch = 00420, train loss = 0.649987, test loss = 0.805495.\n",
      "Cluster 15: epoch = 00430, train loss = 0.641908, test loss = 0.800503.\n",
      "Cluster 15: epoch = 00440, train loss = 0.633959, test loss = 0.795610.\n",
      "Cluster 15: epoch = 00450, train loss = 0.626140, test loss = 0.790808.\n",
      "Cluster 15: epoch = 00460, train loss = 0.618451, test loss = 0.786099.\n",
      "Cluster 15: epoch = 00470, train loss = 0.610888, test loss = 0.781486.\n",
      "Cluster 15: epoch = 00480, train loss = 0.603453, test loss = 0.776957.\n",
      "Cluster 15: epoch = 00490, train loss = 0.596144, test loss = 0.772516.\n",
      "Cluster 15: epoch = 00500, train loss = 0.588959, test loss = 0.768164.\n",
      "Cluster 15: epoch = 00510, train loss = 0.581897, test loss = 0.763900.\n",
      "Cluster 15: epoch = 00520, train loss = 0.574956, test loss = 0.759720.\n",
      "Cluster 15: epoch = 00530, train loss = 0.568134, test loss = 0.755615.\n",
      "Cluster 15: epoch = 00540, train loss = 0.561431, test loss = 0.751592.\n",
      "Cluster 15: epoch = 00550, train loss = 0.554843, test loss = 0.747643.\n",
      "Cluster 15: epoch = 00560, train loss = 0.548369, test loss = 0.743773.\n",
      "Cluster 15: epoch = 00570, train loss = 0.542007, test loss = 0.739980.\n",
      "Cluster 15: epoch = 00580, train loss = 0.535756, test loss = 0.736260.\n",
      "Cluster 15: epoch = 00590, train loss = 0.529613, test loss = 0.732612.\n",
      "Cluster 15: epoch = 00600, train loss = 0.523576, test loss = 0.729029.\n",
      "Cluster 15: epoch = 00610, train loss = 0.517644, test loss = 0.725523.\n",
      "Cluster 15: epoch = 00620, train loss = 0.511815, test loss = 0.722086.\n",
      "Cluster 15: epoch = 00630, train loss = 0.506085, test loss = 0.718718.\n",
      "Cluster 15: epoch = 00640, train loss = 0.500455, test loss = 0.715407.\n",
      "Cluster 15: epoch = 00650, train loss = 0.494921, test loss = 0.712161.\n",
      "Cluster 15: epoch = 00660, train loss = 0.489482, test loss = 0.708975.\n",
      "Cluster 15: epoch = 00670, train loss = 0.484135, test loss = 0.705845.\n",
      "Cluster 15: epoch = 00680, train loss = 0.478879, test loss = 0.702770.\n",
      "Cluster 15: epoch = 00690, train loss = 0.473712, test loss = 0.699752.\n",
      "Cluster 15: epoch = 00700, train loss = 0.468633, test loss = 0.696786.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 15 done in 0:00:01.765840.\n",
      "Writing the output model to \"./regularized_synonym_phi.k15.trained\".\n",
      "./regularized_synonym_phi.k16.trained\n",
      "Cluster 16: 504 train items and 128 test items available; using 1 steps of 504 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cluster 16: epoch = 00001, train loss = 1.904198, test loss = 1.920006.\n",
      "Cluster 16: epoch = 00010, train loss = 1.814150, test loss = 1.834941.\n",
      "Cluster 16: epoch = 00020, train loss = 1.686591, test loss = 1.714560.\n",
      "Cluster 16: epoch = 00030, train loss = 1.564346, test loss = 1.599305.\n",
      "Cluster 16: epoch = 00040, train loss = 1.460720, test loss = 1.501787.\n",
      "Cluster 16: epoch = 00050, train loss = 1.378801, test loss = 1.424998.\n",
      "Cluster 16: epoch = 00060, train loss = 1.316207, test loss = 1.366766.\n",
      "Cluster 16: epoch = 00070, train loss = 1.268392, test loss = 1.322845.\n",
      "Cluster 16: epoch = 00080, train loss = 1.230710, test loss = 1.288868.\n",
      "Cluster 16: epoch = 00090, train loss = 1.199434, test loss = 1.261304.\n",
      "Cluster 16: epoch = 00100, train loss = 1.171988, test loss = 1.237676.\n",
      "Cluster 16: epoch = 00110, train loss = 1.146786, test loss = 1.216438.\n",
      "Cluster 16: epoch = 00120, train loss = 1.122950, test loss = 1.196706.\n",
      "Cluster 16: epoch = 00130, train loss = 1.100037, test loss = 1.178005.\n",
      "Cluster 16: epoch = 00140, train loss = 1.077844, test loss = 1.160095.\n",
      "Cluster 16: epoch = 00150, train loss = 1.056285, test loss = 1.142855.\n",
      "Cluster 16: epoch = 00160, train loss = 1.035330, test loss = 1.126226.\n",
      "Cluster 16: epoch = 00170, train loss = 1.014968, test loss = 1.110171.\n",
      "Cluster 16: epoch = 00180, train loss = 0.995191, test loss = 1.094667.\n",
      "Cluster 16: epoch = 00190, train loss = 0.975995, test loss = 1.079690.\n",
      "Cluster 16: epoch = 00200, train loss = 0.957365, test loss = 1.065219.\n",
      "Cluster 16: epoch = 00210, train loss = 0.939291, test loss = 1.051241.\n",
      "Cluster 16: epoch = 00220, train loss = 0.921756, test loss = 1.037727.\n",
      "Cluster 16: epoch = 00230, train loss = 0.904744, test loss = 1.024658.\n",
      "Cluster 16: epoch = 00240, train loss = 0.888235, test loss = 1.012016.\n",
      "Cluster 16: epoch = 00250, train loss = 0.872214, test loss = 0.999781.\n",
      "Cluster 16: epoch = 00260, train loss = 0.856661, test loss = 0.987936.\n",
      "Cluster 16: epoch = 00270, train loss = 0.841562, test loss = 0.976460.\n",
      "Cluster 16: epoch = 00280, train loss = 0.826897, test loss = 0.965338.\n",
      "Cluster 16: epoch = 00290, train loss = 0.812650, test loss = 0.954551.\n",
      "Cluster 16: epoch = 00300, train loss = 0.798805, test loss = 0.944083.\n",
      "Cluster 16: epoch = 00310, train loss = 0.785349, test loss = 0.933924.\n",
      "Cluster 16: epoch = 00320, train loss = 0.772266, test loss = 0.924058.\n",
      "Cluster 16: epoch = 00330, train loss = 0.759542, test loss = 0.914470.\n",
      "Cluster 16: epoch = 00340, train loss = 0.747164, test loss = 0.905151.\n",
      "Cluster 16: epoch = 00350, train loss = 0.735121, test loss = 0.896086.\n",
      "Cluster 16: epoch = 00360, train loss = 0.723401, test loss = 0.887264.\n",
      "Cluster 16: epoch = 00370, train loss = 0.711992, test loss = 0.878681.\n",
      "Cluster 16: epoch = 00380, train loss = 0.700883, test loss = 0.870324.\n",
      "Cluster 16: epoch = 00390, train loss = 0.690064, test loss = 0.862181.\n",
      "Cluster 16: epoch = 00400, train loss = 0.679527, test loss = 0.854247.\n",
      "Cluster 16: epoch = 00410, train loss = 0.669261, test loss = 0.846516.\n",
      "Cluster 16: epoch = 00420, train loss = 0.659257, test loss = 0.838974.\n",
      "Cluster 16: epoch = 00430, train loss = 0.649508, test loss = 0.831618.\n",
      "Cluster 16: epoch = 00440, train loss = 0.640005, test loss = 0.824444.\n",
      "Cluster 16: epoch = 00450, train loss = 0.630740, test loss = 0.817446.\n",
      "Cluster 16: epoch = 00460, train loss = 0.621705, test loss = 0.810615.\n",
      "Cluster 16: epoch = 00470, train loss = 0.612895, test loss = 0.803944.\n",
      "Cluster 16: epoch = 00480, train loss = 0.604300, test loss = 0.797432.\n",
      "Cluster 16: epoch = 00490, train loss = 0.595915, test loss = 0.791070.\n",
      "Cluster 16: epoch = 00500, train loss = 0.587734, test loss = 0.784851.\n",
      "Cluster 16: epoch = 00510, train loss = 0.579751, test loss = 0.778775.\n",
      "Cluster 16: epoch = 00520, train loss = 0.571958, test loss = 0.772836.\n",
      "Cluster 16: epoch = 00530, train loss = 0.564351, test loss = 0.767026.\n",
      "Cluster 16: epoch = 00540, train loss = 0.556924, test loss = 0.761346.\n",
      "Cluster 16: epoch = 00550, train loss = 0.549673, test loss = 0.755791.\n",
      "Cluster 16: epoch = 00560, train loss = 0.542591, test loss = 0.750357.\n",
      "Cluster 16: epoch = 00570, train loss = 0.535674, test loss = 0.745035.\n",
      "Cluster 16: epoch = 00580, train loss = 0.528918, test loss = 0.739829.\n",
      "Cluster 16: epoch = 00590, train loss = 0.522316, test loss = 0.734732.\n",
      "Cluster 16: epoch = 00600, train loss = 0.515865, test loss = 0.729746.\n",
      "Cluster 16: epoch = 00610, train loss = 0.509561, test loss = 0.724864.\n",
      "Cluster 16: epoch = 00620, train loss = 0.503400, test loss = 0.720083.\n",
      "Cluster 16: epoch = 00630, train loss = 0.497377, test loss = 0.715397.\n",
      "Cluster 16: epoch = 00640, train loss = 0.491489, test loss = 0.710804.\n",
      "Cluster 16: epoch = 00650, train loss = 0.485732, test loss = 0.706304.\n",
      "Cluster 16: epoch = 00660, train loss = 0.480101, test loss = 0.701897.\n",
      "Cluster 16: epoch = 00670, train loss = 0.474595, test loss = 0.697578.\n",
      "Cluster 16: epoch = 00680, train loss = 0.469208, test loss = 0.693342.\n",
      "Cluster 16: epoch = 00690, train loss = 0.463939, test loss = 0.689188.\n",
      "Cluster 16: epoch = 00700, train loss = 0.458784, test loss = 0.685118.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 16 done in 0:00:04.453643.\n",
      "Writing the output model to \"./regularized_synonym_phi.k16.trained\".\n",
      "./regularized_synonym_phi.k17.trained\n",
      "Cluster 17: 138 train items and 44 test items available; using 1 steps of 138 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cluster 17: epoch = 00001, train loss = 1.868498, test loss = 1.855383.\n",
      "Cluster 17: epoch = 00010, train loss = 1.814188, test loss = 1.801106.\n",
      "Cluster 17: epoch = 00020, train loss = 1.725308, test loss = 1.712537.\n",
      "Cluster 17: epoch = 00030, train loss = 1.624779, test loss = 1.612804.\n",
      "Cluster 17: epoch = 00040, train loss = 1.522182, test loss = 1.511632.\n",
      "Cluster 17: epoch = 00050, train loss = 1.423374, test loss = 1.414955.\n",
      "Cluster 17: epoch = 00060, train loss = 1.331819, test loss = 1.326264.\n",
      "Cluster 17: epoch = 00070, train loss = 1.249316, test loss = 1.247340.\n",
      "Cluster 17: epoch = 00080, train loss = 1.176483, test loss = 1.178746.\n",
      "Cluster 17: epoch = 00090, train loss = 1.113159, test loss = 1.120247.\n",
      "Cluster 17: epoch = 00100, train loss = 1.058669, test loss = 1.071085.\n",
      "Cluster 17: epoch = 00110, train loss = 1.012061, test loss = 1.030220.\n",
      "Cluster 17: epoch = 00120, train loss = 0.972264, test loss = 0.996497.\n",
      "Cluster 17: epoch = 00130, train loss = 0.938198, test loss = 0.968756.\n",
      "Cluster 17: epoch = 00140, train loss = 0.908847, test loss = 0.945913.\n",
      "Cluster 17: epoch = 00150, train loss = 0.883295, test loss = 0.926991.\n",
      "Cluster 17: epoch = 00160, train loss = 0.860762, test loss = 0.911160.\n",
      "Cluster 17: epoch = 00170, train loss = 0.840590, test loss = 0.897716.\n",
      "Cluster 17: epoch = 00180, train loss = 0.822244, test loss = 0.886095.\n",
      "Cluster 17: epoch = 00190, train loss = 0.805306, test loss = 0.875857.\n",
      "Cluster 17: epoch = 00200, train loss = 0.789451, test loss = 0.866655.\n",
      "Cluster 17: epoch = 00210, train loss = 0.774428, test loss = 0.858220.\n",
      "Cluster 17: epoch = 00220, train loss = 0.760057, test loss = 0.850370.\n",
      "Cluster 17: epoch = 00230, train loss = 0.746204, test loss = 0.842959.\n",
      "Cluster 17: epoch = 00240, train loss = 0.732772, test loss = 0.835889.\n",
      "Cluster 17: epoch = 00250, train loss = 0.719699, test loss = 0.829093.\n",
      "Cluster 17: epoch = 00260, train loss = 0.706935, test loss = 0.822521.\n",
      "Cluster 17: epoch = 00270, train loss = 0.694454, test loss = 0.816137.\n",
      "Cluster 17: epoch = 00280, train loss = 0.682233, test loss = 0.809917.\n",
      "Cluster 17: epoch = 00290, train loss = 0.670260, test loss = 0.803853.\n",
      "Cluster 17: epoch = 00300, train loss = 0.658527, test loss = 0.797937.\n",
      "Cluster 17: epoch = 00310, train loss = 0.647030, test loss = 0.792168.\n",
      "Cluster 17: epoch = 00320, train loss = 0.635764, test loss = 0.786543.\n",
      "Cluster 17: epoch = 00330, train loss = 0.624727, test loss = 0.781050.\n",
      "Cluster 17: epoch = 00340, train loss = 0.613918, test loss = 0.775693.\n",
      "Cluster 17: epoch = 00350, train loss = 0.603334, test loss = 0.770467.\n",
      "Cluster 17: epoch = 00360, train loss = 0.592975, test loss = 0.765376.\n",
      "Cluster 17: epoch = 00370, train loss = 0.582837, test loss = 0.760418.\n",
      "Cluster 17: epoch = 00380, train loss = 0.572919, test loss = 0.755590.\n",
      "Cluster 17: epoch = 00390, train loss = 0.563217, test loss = 0.750894.\n",
      "Cluster 17: epoch = 00400, train loss = 0.553728, test loss = 0.746319.\n",
      "Cluster 17: epoch = 00410, train loss = 0.544452, test loss = 0.741865.\n",
      "Cluster 17: epoch = 00420, train loss = 0.535383, test loss = 0.737535.\n",
      "Cluster 17: epoch = 00430, train loss = 0.526517, test loss = 0.733326.\n",
      "Cluster 17: epoch = 00440, train loss = 0.517851, test loss = 0.729233.\n",
      "Cluster 17: epoch = 00450, train loss = 0.509380, test loss = 0.725250.\n",
      "Cluster 17: epoch = 00460, train loss = 0.501100, test loss = 0.721376.\n",
      "Cluster 17: epoch = 00470, train loss = 0.493008, test loss = 0.717604.\n",
      "Cluster 17: epoch = 00480, train loss = 0.485100, test loss = 0.713932.\n",
      "Cluster 17: epoch = 00490, train loss = 0.477371, test loss = 0.710360.\n",
      "Cluster 17: epoch = 00500, train loss = 0.469817, test loss = 0.706885.\n",
      "Cluster 17: epoch = 00510, train loss = 0.462435, test loss = 0.703510.\n",
      "Cluster 17: epoch = 00520, train loss = 0.455219, test loss = 0.700225.\n",
      "Cluster 17: epoch = 00530, train loss = 0.448165, test loss = 0.697030.\n",
      "Cluster 17: epoch = 00540, train loss = 0.441269, test loss = 0.693917.\n",
      "Cluster 17: epoch = 00550, train loss = 0.434527, test loss = 0.690886.\n",
      "Cluster 17: epoch = 00560, train loss = 0.427936, test loss = 0.687935.\n",
      "Cluster 17: epoch = 00570, train loss = 0.421492, test loss = 0.685057.\n",
      "Cluster 17: epoch = 00580, train loss = 0.415189, test loss = 0.682248.\n",
      "Cluster 17: epoch = 00590, train loss = 0.409025, test loss = 0.679512.\n",
      "Cluster 17: epoch = 00600, train loss = 0.402996, test loss = 0.676851.\n",
      "Cluster 17: epoch = 00610, train loss = 0.397097, test loss = 0.674250.\n",
      "Cluster 17: epoch = 00620, train loss = 0.391327, test loss = 0.671712.\n",
      "Cluster 17: epoch = 00630, train loss = 0.385681, test loss = 0.669240.\n",
      "Cluster 17: epoch = 00640, train loss = 0.380155, test loss = 0.666831.\n",
      "Cluster 17: epoch = 00650, train loss = 0.374748, test loss = 0.664479.\n",
      "Cluster 17: epoch = 00660, train loss = 0.369456, test loss = 0.662183.\n",
      "Cluster 17: epoch = 00670, train loss = 0.364276, test loss = 0.659938.\n",
      "Cluster 17: epoch = 00680, train loss = 0.359203, test loss = 0.657741.\n",
      "Cluster 17: epoch = 00690, train loss = 0.354236, test loss = 0.655597.\n",
      "Cluster 17: epoch = 00700, train loss = 0.349371, test loss = 0.653503.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 17 done in 0:00:01.807396.\n",
      "Writing the output model to \"./regularized_synonym_phi.k17.trained\".\n",
      "./regularized_synonym_phi.k18.trained\n",
      "Cluster 18: 619 train items and 131 test items available; using 1 steps of 619 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cluster 18: epoch = 00001, train loss = 1.943872, test loss = 1.948825.\n",
      "Cluster 18: epoch = 00010, train loss = 1.824663, test loss = 1.835077.\n",
      "Cluster 18: epoch = 00020, train loss = 1.666035, test loss = 1.684326.\n",
      "Cluster 18: epoch = 00030, train loss = 1.523754, test loss = 1.549794.\n",
      "Cluster 18: epoch = 00040, train loss = 1.411722, test loss = 1.444719.\n",
      "Cluster 18: epoch = 00050, train loss = 1.329880, test loss = 1.369028.\n",
      "Cluster 18: epoch = 00060, train loss = 1.271830, test loss = 1.316581.\n",
      "Cluster 18: epoch = 00070, train loss = 1.229829, test loss = 1.279936.\n",
      "Cluster 18: epoch = 00080, train loss = 1.197439, test loss = 1.252877.\n",
      "Cluster 18: epoch = 00090, train loss = 1.170293, test loss = 1.231152.\n",
      "Cluster 18: epoch = 00100, train loss = 1.145840, test loss = 1.212237.\n",
      "Cluster 18: epoch = 00110, train loss = 1.122756, test loss = 1.194792.\n",
      "Cluster 18: epoch = 00120, train loss = 1.100428, test loss = 1.178155.\n",
      "Cluster 18: epoch = 00130, train loss = 1.078607, test loss = 1.162029.\n",
      "Cluster 18: epoch = 00140, train loss = 1.057213, test loss = 1.146290.\n",
      "Cluster 18: epoch = 00150, train loss = 1.036234, test loss = 1.130898.\n",
      "Cluster 18: epoch = 00160, train loss = 1.015690, test loss = 1.115844.\n",
      "Cluster 18: epoch = 00170, train loss = 0.995599, test loss = 1.101130.\n",
      "Cluster 18: epoch = 00180, train loss = 0.975981, test loss = 1.086763.\n",
      "Cluster 18: epoch = 00190, train loss = 0.956851, test loss = 1.072749.\n",
      "Cluster 18: epoch = 00200, train loss = 0.938217, test loss = 1.059092.\n",
      "Cluster 18: epoch = 00210, train loss = 0.920082, test loss = 1.045797.\n",
      "Cluster 18: epoch = 00220, train loss = 0.902447, test loss = 1.032861.\n",
      "Cluster 18: epoch = 00230, train loss = 0.885308, test loss = 1.020278.\n",
      "Cluster 18: epoch = 00240, train loss = 0.868659, test loss = 1.008042.\n",
      "Cluster 18: epoch = 00250, train loss = 0.852492, test loss = 0.996147.\n",
      "Cluster 18: epoch = 00260, train loss = 0.836796, test loss = 0.984584.\n",
      "Cluster 18: epoch = 00270, train loss = 0.821559, test loss = 0.973349.\n",
      "Cluster 18: epoch = 00280, train loss = 0.806770, test loss = 0.962428.\n",
      "Cluster 18: epoch = 00290, train loss = 0.792416, test loss = 0.951810.\n",
      "Cluster 18: epoch = 00300, train loss = 0.778485, test loss = 0.941486.\n",
      "Cluster 18: epoch = 00310, train loss = 0.764962, test loss = 0.931445.\n",
      "Cluster 18: epoch = 00320, train loss = 0.751835, test loss = 0.921680.\n",
      "Cluster 18: epoch = 00330, train loss = 0.739092, test loss = 0.912179.\n",
      "Cluster 18: epoch = 00340, train loss = 0.726719, test loss = 0.902935.\n",
      "Cluster 18: epoch = 00350, train loss = 0.714704, test loss = 0.893936.\n",
      "Cluster 18: epoch = 00360, train loss = 0.703036, test loss = 0.885175.\n",
      "Cluster 18: epoch = 00370, train loss = 0.691701, test loss = 0.876639.\n",
      "Cluster 18: epoch = 00380, train loss = 0.680688, test loss = 0.868328.\n",
      "Cluster 18: epoch = 00390, train loss = 0.669988, test loss = 0.860231.\n",
      "Cluster 18: epoch = 00400, train loss = 0.659589, test loss = 0.852337.\n",
      "Cluster 18: epoch = 00410, train loss = 0.649479, test loss = 0.844641.\n",
      "Cluster 18: epoch = 00420, train loss = 0.639651, test loss = 0.837134.\n",
      "Cluster 18: epoch = 00430, train loss = 0.630094, test loss = 0.829813.\n",
      "Cluster 18: epoch = 00440, train loss = 0.620799, test loss = 0.822673.\n",
      "Cluster 18: epoch = 00450, train loss = 0.611758, test loss = 0.815704.\n",
      "Cluster 18: epoch = 00460, train loss = 0.602963, test loss = 0.808901.\n",
      "Cluster 18: epoch = 00470, train loss = 0.594405, test loss = 0.802258.\n",
      "Cluster 18: epoch = 00480, train loss = 0.586076, test loss = 0.795772.\n",
      "Cluster 18: epoch = 00490, train loss = 0.577968, test loss = 0.789435.\n",
      "Cluster 18: epoch = 00500, train loss = 0.570075, test loss = 0.783244.\n",
      "Cluster 18: epoch = 00510, train loss = 0.562390, test loss = 0.777197.\n",
      "Cluster 18: epoch = 00520, train loss = 0.554906, test loss = 0.771289.\n",
      "Cluster 18: epoch = 00530, train loss = 0.547617, test loss = 0.765515.\n",
      "Cluster 18: epoch = 00540, train loss = 0.540516, test loss = 0.759867.\n",
      "Cluster 18: epoch = 00550, train loss = 0.533598, test loss = 0.754347.\n",
      "Cluster 18: epoch = 00560, train loss = 0.526857, test loss = 0.748949.\n",
      "Cluster 18: epoch = 00570, train loss = 0.520287, test loss = 0.743670.\n",
      "Cluster 18: epoch = 00580, train loss = 0.513883, test loss = 0.738502.\n",
      "Cluster 18: epoch = 00590, train loss = 0.507640, test loss = 0.733446.\n",
      "Cluster 18: epoch = 00600, train loss = 0.501552, test loss = 0.728501.\n",
      "Cluster 18: epoch = 00610, train loss = 0.495616, test loss = 0.723663.\n",
      "Cluster 18: epoch = 00620, train loss = 0.489826, test loss = 0.718926.\n",
      "Cluster 18: epoch = 00630, train loss = 0.484178, test loss = 0.714283.\n",
      "Cluster 18: epoch = 00640, train loss = 0.478669, test loss = 0.709742.\n",
      "Cluster 18: epoch = 00650, train loss = 0.473292, test loss = 0.705295.\n",
      "Cluster 18: epoch = 00660, train loss = 0.468044, test loss = 0.700939.\n",
      "Cluster 18: epoch = 00670, train loss = 0.462923, test loss = 0.696673.\n",
      "Cluster 18: epoch = 00680, train loss = 0.457923, test loss = 0.692491.\n",
      "Cluster 18: epoch = 00690, train loss = 0.453042, test loss = 0.688390.\n",
      "Cluster 18: epoch = 00700, train loss = 0.448275, test loss = 0.684377.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 18 done in 0:00:05.595795.\n",
      "Writing the output model to \"./regularized_synonym_phi.k18.trained\".\n",
      "./regularized_synonym_phi.k19.trained\n",
      "Cluster 19: 78 train items and 22 test items available; using 1 steps of 78 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cluster 19: epoch = 00001, train loss = 1.784827, test loss = 1.783569.\n",
      "Cluster 19: epoch = 00010, train loss = 1.741800, test loss = 1.743535.\n",
      "Cluster 19: epoch = 00020, train loss = 1.669019, test loss = 1.675917.\n",
      "Cluster 19: epoch = 00030, train loss = 1.583965, test loss = 1.597070.\n",
      "Cluster 19: epoch = 00040, train loss = 1.494224, test loss = 1.514109.\n",
      "Cluster 19: epoch = 00050, train loss = 1.404765, test loss = 1.431699.\n",
      "Cluster 19: epoch = 00060, train loss = 1.318916, test loss = 1.352963.\n",
      "Cluster 19: epoch = 00070, train loss = 1.238802, test loss = 1.279880.\n",
      "Cluster 19: epoch = 00080, train loss = 1.165632, test loss = 1.213569.\n",
      "Cluster 19: epoch = 00090, train loss = 1.099947, test loss = 1.154514.\n",
      "Cluster 19: epoch = 00100, train loss = 1.041794, test loss = 1.102735.\n",
      "Cluster 19: epoch = 00110, train loss = 0.990879, test loss = 1.057931.\n",
      "Cluster 19: epoch = 00120, train loss = 0.946689, test loss = 1.019591.\n",
      "Cluster 19: epoch = 00130, train loss = 0.908572, test loss = 0.987075.\n",
      "Cluster 19: epoch = 00140, train loss = 0.875817, test loss = 0.959695.\n",
      "Cluster 19: epoch = 00150, train loss = 0.847712, test loss = 0.936757.\n",
      "Cluster 19: epoch = 00160, train loss = 0.823560, test loss = 0.917588.\n",
      "Cluster 19: epoch = 00170, train loss = 0.802728, test loss = 0.901572.\n",
      "Cluster 19: epoch = 00180, train loss = 0.784643, test loss = 0.888160.\n",
      "Cluster 19: epoch = 00190, train loss = 0.768803, test loss = 0.876863.\n",
      "Cluster 19: epoch = 00200, train loss = 0.754780, test loss = 0.867269.\n",
      "Cluster 19: epoch = 00210, train loss = 0.742211, test loss = 0.859029.\n",
      "Cluster 19: epoch = 00220, train loss = 0.730799, test loss = 0.851859.\n",
      "Cluster 19: epoch = 00230, train loss = 0.720305, test loss = 0.845525.\n",
      "Cluster 19: epoch = 00240, train loss = 0.710532, test loss = 0.839842.\n",
      "Cluster 19: epoch = 00250, train loss = 0.701331, test loss = 0.834663.\n",
      "Cluster 19: epoch = 00260, train loss = 0.692582, test loss = 0.829870.\n",
      "Cluster 19: epoch = 00270, train loss = 0.684195, test loss = 0.825378.\n",
      "Cluster 19: epoch = 00280, train loss = 0.676099, test loss = 0.821122.\n",
      "Cluster 19: epoch = 00290, train loss = 0.668244, test loss = 0.817046.\n",
      "Cluster 19: epoch = 00300, train loss = 0.660589, test loss = 0.813115.\n",
      "Cluster 19: epoch = 00310, train loss = 0.653103, test loss = 0.809301.\n",
      "Cluster 19: epoch = 00320, train loss = 0.645768, test loss = 0.805587.\n",
      "Cluster 19: epoch = 00330, train loss = 0.638568, test loss = 0.801959.\n",
      "Cluster 19: epoch = 00340, train loss = 0.631493, test loss = 0.798403.\n",
      "Cluster 19: epoch = 00350, train loss = 0.624537, test loss = 0.794913.\n",
      "Cluster 19: epoch = 00360, train loss = 0.617693, test loss = 0.791484.\n",
      "Cluster 19: epoch = 00370, train loss = 0.610956, test loss = 0.788109.\n",
      "Cluster 19: epoch = 00380, train loss = 0.604324, test loss = 0.784788.\n",
      "Cluster 19: epoch = 00390, train loss = 0.597794, test loss = 0.781523.\n",
      "Cluster 19: epoch = 00400, train loss = 0.591364, test loss = 0.778313.\n",
      "Cluster 19: epoch = 00410, train loss = 0.585033, test loss = 0.775150.\n",
      "Cluster 19: epoch = 00420, train loss = 0.578799, test loss = 0.772039.\n",
      "Cluster 19: epoch = 00430, train loss = 0.572660, test loss = 0.768974.\n",
      "Cluster 19: epoch = 00440, train loss = 0.566617, test loss = 0.765955.\n",
      "Cluster 19: epoch = 00450, train loss = 0.560667, test loss = 0.762983.\n",
      "Cluster 19: epoch = 00460, train loss = 0.554810, test loss = 0.760060.\n",
      "Cluster 19: epoch = 00470, train loss = 0.549042, test loss = 0.757180.\n",
      "Cluster 19: epoch = 00480, train loss = 0.543364, test loss = 0.754345.\n",
      "Cluster 19: epoch = 00490, train loss = 0.537773, test loss = 0.751554.\n",
      "Cluster 19: epoch = 00500, train loss = 0.532268, test loss = 0.748807.\n",
      "Cluster 19: epoch = 00510, train loss = 0.526847, test loss = 0.746105.\n",
      "Cluster 19: epoch = 00520, train loss = 0.521508, test loss = 0.743445.\n",
      "Cluster 19: epoch = 00530, train loss = 0.516251, test loss = 0.740825.\n",
      "Cluster 19: epoch = 00540, train loss = 0.511072, test loss = 0.738243.\n",
      "Cluster 19: epoch = 00550, train loss = 0.505972, test loss = 0.735701.\n",
      "Cluster 19: epoch = 00560, train loss = 0.500949, test loss = 0.733197.\n",
      "Cluster 19: epoch = 00570, train loss = 0.496000, test loss = 0.730727.\n",
      "Cluster 19: epoch = 00580, train loss = 0.491125, test loss = 0.728292.\n",
      "Cluster 19: epoch = 00590, train loss = 0.486321, test loss = 0.725893.\n",
      "Cluster 19: epoch = 00600, train loss = 0.481587, test loss = 0.723528.\n",
      "Cluster 19: epoch = 00610, train loss = 0.476922, test loss = 0.721197.\n",
      "Cluster 19: epoch = 00620, train loss = 0.472323, test loss = 0.718899.\n",
      "Cluster 19: epoch = 00630, train loss = 0.467791, test loss = 0.716633.\n",
      "Cluster 19: epoch = 00640, train loss = 0.463323, test loss = 0.714397.\n",
      "Cluster 19: epoch = 00650, train loss = 0.458918, test loss = 0.712197.\n",
      "Cluster 19: epoch = 00660, train loss = 0.454574, test loss = 0.710025.\n",
      "Cluster 19: epoch = 00670, train loss = 0.450290, test loss = 0.707879.\n",
      "Cluster 19: epoch = 00680, train loss = 0.446065, test loss = 0.705761.\n",
      "Cluster 19: epoch = 00690, train loss = 0.441898, test loss = 0.703671.\n",
      "Cluster 19: epoch = 00700, train loss = 0.437787, test loss = 0.701606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 19 done in 0:00:01.530375.\n",
      "Writing the output model to \"./regularized_synonym_phi.k19.trained\".\n",
      "./regularized_synonym_phi.k20.trained\n",
      "Cluster 20: 696 train items and 186 test items available; using 1 steps of 696 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cluster 20: epoch = 00001, train loss = 1.932372, test loss = 1.913635.\n",
      "Cluster 20: epoch = 00010, train loss = 1.813036, test loss = 1.791687.\n",
      "Cluster 20: epoch = 00020, train loss = 1.655802, test loss = 1.632156.\n",
      "Cluster 20: epoch = 00030, train loss = 1.517001, test loss = 1.492912.\n",
      "Cluster 20: epoch = 00040, train loss = 1.409631, test loss = 1.387164.\n",
      "Cluster 20: epoch = 00050, train loss = 1.332125, test loss = 1.313049.\n",
      "Cluster 20: epoch = 00060, train loss = 1.276874, test loss = 1.262475.\n",
      "Cluster 20: epoch = 00070, train loss = 1.235687, test loss = 1.226791.\n",
      "Cluster 20: epoch = 00080, train loss = 1.202345, test loss = 1.199430.\n",
      "Cluster 20: epoch = 00090, train loss = 1.173033, test loss = 1.176358.\n",
      "Cluster 20: epoch = 00100, train loss = 1.145760, test loss = 1.155440.\n",
      "Cluster 20: epoch = 00110, train loss = 1.119619, test loss = 1.135695.\n",
      "Cluster 20: epoch = 00120, train loss = 1.094261, test loss = 1.116719.\n",
      "Cluster 20: epoch = 00130, train loss = 1.069578, test loss = 1.098367.\n",
      "Cluster 20: epoch = 00140, train loss = 1.045559, test loss = 1.080594.\n",
      "Cluster 20: epoch = 00150, train loss = 1.022219, test loss = 1.063399.\n",
      "Cluster 20: epoch = 00160, train loss = 0.999575, test loss = 1.046786.\n",
      "Cluster 20: epoch = 00170, train loss = 0.977642, test loss = 1.030764.\n",
      "Cluster 20: epoch = 00180, train loss = 0.956421, test loss = 1.015325.\n",
      "Cluster 20: epoch = 00190, train loss = 0.935910, test loss = 1.000454.\n",
      "Cluster 20: epoch = 00200, train loss = 0.916097, test loss = 0.986129.\n",
      "Cluster 20: epoch = 00210, train loss = 0.896971, test loss = 0.972346.\n",
      "Cluster 20: epoch = 00220, train loss = 0.878510, test loss = 0.959075.\n",
      "Cluster 20: epoch = 00230, train loss = 0.860696, test loss = 0.946297.\n",
      "Cluster 20: epoch = 00240, train loss = 0.843506, test loss = 0.933990.\n",
      "Cluster 20: epoch = 00250, train loss = 0.826916, test loss = 0.922126.\n",
      "Cluster 20: epoch = 00260, train loss = 0.810905, test loss = 0.910686.\n",
      "Cluster 20: epoch = 00270, train loss = 0.795446, test loss = 0.899653.\n",
      "Cluster 20: epoch = 00280, train loss = 0.780517, test loss = 0.889003.\n",
      "Cluster 20: epoch = 00290, train loss = 0.766097, test loss = 0.878707.\n",
      "Cluster 20: epoch = 00300, train loss = 0.752164, test loss = 0.868752.\n",
      "Cluster 20: epoch = 00310, train loss = 0.738697, test loss = 0.859123.\n",
      "Cluster 20: epoch = 00320, train loss = 0.725675, test loss = 0.849799.\n",
      "Cluster 20: epoch = 00330, train loss = 0.713078, test loss = 0.840773.\n",
      "Cluster 20: epoch = 00340, train loss = 0.700890, test loss = 0.832022.\n",
      "Cluster 20: epoch = 00350, train loss = 0.689094, test loss = 0.823533.\n",
      "Cluster 20: epoch = 00360, train loss = 0.677670, test loss = 0.815294.\n",
      "Cluster 20: epoch = 00370, train loss = 0.666606, test loss = 0.807297.\n",
      "Cluster 20: epoch = 00380, train loss = 0.655885, test loss = 0.799530.\n",
      "Cluster 20: epoch = 00390, train loss = 0.645495, test loss = 0.791980.\n",
      "Cluster 20: epoch = 00400, train loss = 0.635421, test loss = 0.784634.\n",
      "Cluster 20: epoch = 00410, train loss = 0.625651, test loss = 0.777486.\n",
      "Cluster 20: epoch = 00420, train loss = 0.616173, test loss = 0.770533.\n",
      "Cluster 20: epoch = 00430, train loss = 0.606976, test loss = 0.763767.\n",
      "Cluster 20: epoch = 00440, train loss = 0.598049, test loss = 0.757180.\n",
      "Cluster 20: epoch = 00450, train loss = 0.589381, test loss = 0.750754.\n",
      "Cluster 20: epoch = 00460, train loss = 0.580963, test loss = 0.744494.\n",
      "Cluster 20: epoch = 00470, train loss = 0.572785, test loss = 0.738393.\n",
      "Cluster 20: epoch = 00480, train loss = 0.564839, test loss = 0.732443.\n",
      "Cluster 20: epoch = 00490, train loss = 0.557116, test loss = 0.726634.\n",
      "Cluster 20: epoch = 00500, train loss = 0.549608, test loss = 0.720961.\n",
      "Cluster 20: epoch = 00510, train loss = 0.542308, test loss = 0.715423.\n",
      "Cluster 20: epoch = 00520, train loss = 0.535208, test loss = 0.710022.\n",
      "Cluster 20: epoch = 00530, train loss = 0.528300, test loss = 0.704749.\n",
      "Cluster 20: epoch = 00540, train loss = 0.521580, test loss = 0.699591.\n",
      "Cluster 20: epoch = 00550, train loss = 0.515039, test loss = 0.694555.\n",
      "Cluster 20: epoch = 00560, train loss = 0.508672, test loss = 0.689633.\n",
      "Cluster 20: epoch = 00570, train loss = 0.502472, test loss = 0.684825.\n",
      "Cluster 20: epoch = 00580, train loss = 0.496435, test loss = 0.680124.\n",
      "Cluster 20: epoch = 00590, train loss = 0.490554, test loss = 0.675523.\n",
      "Cluster 20: epoch = 00600, train loss = 0.484824, test loss = 0.671021.\n",
      "Cluster 20: epoch = 00610, train loss = 0.479242, test loss = 0.666614.\n",
      "Cluster 20: epoch = 00620, train loss = 0.473801, test loss = 0.662304.\n",
      "Cluster 20: epoch = 00630, train loss = 0.468497, test loss = 0.658085.\n",
      "Cluster 20: epoch = 00640, train loss = 0.463325, test loss = 0.653952.\n",
      "Cluster 20: epoch = 00650, train loss = 0.458282, test loss = 0.649908.\n",
      "Cluster 20: epoch = 00660, train loss = 0.453363, test loss = 0.645949.\n",
      "Cluster 20: epoch = 00670, train loss = 0.448565, test loss = 0.642071.\n",
      "Cluster 20: epoch = 00680, train loss = 0.443882, test loss = 0.638271.\n",
      "Cluster 20: epoch = 00690, train loss = 0.439313, test loss = 0.634546.\n",
      "Cluster 20: epoch = 00700, train loss = 0.434854, test loss = 0.630895.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 20 done in 0:00:06.365988.\n",
      "Writing the output model to \"./regularized_synonym_phi.k20.trained\".\n",
      "./regularized_synonym_phi.k21.trained\n",
      "Cluster 21: 79 train items and 11 test items available; using 1 steps of 79 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cluster 21: epoch = 00001, train loss = 1.944195, test loss = 1.901215.\n",
      "Cluster 21: epoch = 00010, train loss = 1.904616, test loss = 1.862798.\n",
      "Cluster 21: epoch = 00020, train loss = 1.837610, test loss = 1.797843.\n",
      "Cluster 21: epoch = 00030, train loss = 1.758744, test loss = 1.721498.\n",
      "Cluster 21: epoch = 00040, train loss = 1.674540, test loss = 1.640111.\n",
      "Cluster 21: epoch = 00050, train loss = 1.589282, test loss = 1.557857.\n",
      "Cluster 21: epoch = 00060, train loss = 1.505912, test loss = 1.477597.\n",
      "Cluster 21: epoch = 00070, train loss = 1.426416, test loss = 1.401267.\n",
      "Cluster 21: epoch = 00080, train loss = 1.352071, test loss = 1.330109.\n",
      "Cluster 21: epoch = 00090, train loss = 1.283615, test loss = 1.264839.\n",
      "Cluster 21: epoch = 00100, train loss = 1.221360, test loss = 1.205760.\n",
      "Cluster 21: epoch = 00110, train loss = 1.165326, test loss = 1.152886.\n",
      "Cluster 21: epoch = 00120, train loss = 1.115310, test loss = 1.106013.\n",
      "Cluster 21: epoch = 00130, train loss = 1.070957, test loss = 1.064794.\n",
      "Cluster 21: epoch = 00140, train loss = 1.031832, test loss = 1.028798.\n",
      "Cluster 21: epoch = 00150, train loss = 0.997419, test loss = 0.997518.\n",
      "Cluster 21: epoch = 00160, train loss = 0.967213, test loss = 0.970455.\n",
      "Cluster 21: epoch = 00170, train loss = 0.940685, test loss = 0.947091.\n",
      "Cluster 21: epoch = 00180, train loss = 0.917346, test loss = 0.926942.\n",
      "Cluster 21: epoch = 00190, train loss = 0.896744, test loss = 0.909563.\n",
      "Cluster 21: epoch = 00200, train loss = 0.878460, test loss = 0.894536.\n",
      "Cluster 21: epoch = 00210, train loss = 0.862119, test loss = 0.881494.\n",
      "Cluster 21: epoch = 00220, train loss = 0.847395, test loss = 0.870107.\n",
      "Cluster 21: epoch = 00230, train loss = 0.834002, test loss = 0.860092.\n",
      "Cluster 21: epoch = 00240, train loss = 0.821698, test loss = 0.851206.\n",
      "Cluster 21: epoch = 00250, train loss = 0.810289, test loss = 0.843254.\n",
      "Cluster 21: epoch = 00260, train loss = 0.799596, test loss = 0.836060.\n",
      "Cluster 21: epoch = 00270, train loss = 0.789489, test loss = 0.829490.\n",
      "Cluster 21: epoch = 00280, train loss = 0.779849, test loss = 0.823421.\n",
      "Cluster 21: epoch = 00290, train loss = 0.770587, test loss = 0.817764.\n",
      "Cluster 21: epoch = 00300, train loss = 0.761633, test loss = 0.812440.\n",
      "Cluster 21: epoch = 00310, train loss = 0.752925, test loss = 0.807384.\n",
      "Cluster 21: epoch = 00320, train loss = 0.744420, test loss = 0.802553.\n",
      "Cluster 21: epoch = 00330, train loss = 0.736084, test loss = 0.797905.\n",
      "Cluster 21: epoch = 00340, train loss = 0.727888, test loss = 0.793407.\n",
      "Cluster 21: epoch = 00350, train loss = 0.719814, test loss = 0.789051.\n",
      "Cluster 21: epoch = 00360, train loss = 0.711849, test loss = 0.784809.\n",
      "Cluster 21: epoch = 00370, train loss = 0.703980, test loss = 0.780670.\n",
      "Cluster 21: epoch = 00380, train loss = 0.696200, test loss = 0.776615.\n",
      "Cluster 21: epoch = 00390, train loss = 0.688503, test loss = 0.772640.\n",
      "Cluster 21: epoch = 00400, train loss = 0.680885, test loss = 0.768743.\n",
      "Cluster 21: epoch = 00410, train loss = 0.673342, test loss = 0.764921.\n",
      "Cluster 21: epoch = 00420, train loss = 0.665875, test loss = 0.761163.\n",
      "Cluster 21: epoch = 00430, train loss = 0.658483, test loss = 0.757471.\n",
      "Cluster 21: epoch = 00440, train loss = 0.651165, test loss = 0.753838.\n",
      "Cluster 21: epoch = 00450, train loss = 0.643920, test loss = 0.750263.\n",
      "Cluster 21: epoch = 00460, train loss = 0.636750, test loss = 0.746746.\n",
      "Cluster 21: epoch = 00470, train loss = 0.629654, test loss = 0.743289.\n",
      "Cluster 21: epoch = 00480, train loss = 0.622633, test loss = 0.739891.\n",
      "Cluster 21: epoch = 00490, train loss = 0.615687, test loss = 0.736546.\n",
      "Cluster 21: epoch = 00500, train loss = 0.608817, test loss = 0.733258.\n",
      "Cluster 21: epoch = 00510, train loss = 0.602022, test loss = 0.730024.\n",
      "Cluster 21: epoch = 00520, train loss = 0.595303, test loss = 0.726839.\n",
      "Cluster 21: epoch = 00530, train loss = 0.588661, test loss = 0.723704.\n",
      "Cluster 21: epoch = 00540, train loss = 0.582096, test loss = 0.720623.\n",
      "Cluster 21: epoch = 00550, train loss = 0.575607, test loss = 0.717590.\n",
      "Cluster 21: epoch = 00560, train loss = 0.569195, test loss = 0.714606.\n",
      "Cluster 21: epoch = 00570, train loss = 0.562860, test loss = 0.711672.\n",
      "Cluster 21: epoch = 00580, train loss = 0.556601, test loss = 0.708788.\n",
      "Cluster 21: epoch = 00590, train loss = 0.550419, test loss = 0.705951.\n",
      "Cluster 21: epoch = 00600, train loss = 0.544312, test loss = 0.703161.\n",
      "Cluster 21: epoch = 00610, train loss = 0.538282, test loss = 0.700415.\n",
      "Cluster 21: epoch = 00620, train loss = 0.532327, test loss = 0.697708.\n",
      "Cluster 21: epoch = 00630, train loss = 0.526447, test loss = 0.695047.\n",
      "Cluster 21: epoch = 00640, train loss = 0.520642, test loss = 0.692434.\n",
      "Cluster 21: epoch = 00650, train loss = 0.514911, test loss = 0.689867.\n",
      "Cluster 21: epoch = 00660, train loss = 0.509254, test loss = 0.687341.\n",
      "Cluster 21: epoch = 00670, train loss = 0.503670, test loss = 0.684849.\n",
      "Cluster 21: epoch = 00680, train loss = 0.498159, test loss = 0.682402.\n",
      "Cluster 21: epoch = 00690, train loss = 0.492719, test loss = 0.679994.\n",
      "Cluster 21: epoch = 00700, train loss = 0.487349, test loss = 0.677623.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 21 done in 0:00:01.557277.\n",
      "Writing the output model to \"./regularized_synonym_phi.k21.trained\".\n",
      "./regularized_synonym_phi.k22.trained\n",
      "Cluster 22: 123 train items and 29 test items available; using 1 steps of 123 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cluster 22: epoch = 00001, train loss = 1.944688, test loss = 1.900849.\n",
      "Cluster 22: epoch = 00010, train loss = 1.871367, test loss = 1.833332.\n",
      "Cluster 22: epoch = 00020, train loss = 1.752593, test loss = 1.724068.\n",
      "Cluster 22: epoch = 00030, train loss = 1.620546, test loss = 1.602707.\n",
      "Cluster 22: epoch = 00040, train loss = 1.488899, test loss = 1.481835.\n",
      "Cluster 22: epoch = 00050, train loss = 1.365747, test loss = 1.368910.\n",
      "Cluster 22: epoch = 00060, train loss = 1.255546, test loss = 1.268031.\n",
      "Cluster 22: epoch = 00070, train loss = 1.160183, test loss = 1.180936.\n",
      "Cluster 22: epoch = 00080, train loss = 1.079797, test loss = 1.107758.\n",
      "Cluster 22: epoch = 00090, train loss = 1.013428, test loss = 1.047612.\n",
      "Cluster 22: epoch = 00100, train loss = 0.959499, test loss = 0.999042.\n",
      "Cluster 22: epoch = 00110, train loss = 0.916160, test loss = 0.960344.\n",
      "Cluster 22: epoch = 00120, train loss = 0.881536, test loss = 0.929783.\n",
      "Cluster 22: epoch = 00130, train loss = 0.853866, test loss = 0.905732.\n",
      "Cluster 22: epoch = 00140, train loss = 0.831608, test loss = 0.886763.\n",
      "Cluster 22: epoch = 00150, train loss = 0.813464, test loss = 0.871673.\n",
      "Cluster 22: epoch = 00160, train loss = 0.798380, test loss = 0.859481.\n",
      "Cluster 22: epoch = 00170, train loss = 0.785530, test loss = 0.849412.\n",
      "Cluster 22: epoch = 00180, train loss = 0.774271, test loss = 0.840867.\n",
      "Cluster 22: epoch = 00190, train loss = 0.764131, test loss = 0.833404.\n",
      "Cluster 22: epoch = 00200, train loss = 0.754771, test loss = 0.826699.\n",
      "Cluster 22: epoch = 00210, train loss = 0.745943, test loss = 0.820523.\n",
      "Cluster 22: epoch = 00220, train loss = 0.737483, test loss = 0.814711.\n",
      "Cluster 22: epoch = 00230, train loss = 0.729274, test loss = 0.809154.\n",
      "Cluster 22: epoch = 00240, train loss = 0.721239, test loss = 0.803776.\n",
      "Cluster 22: epoch = 00250, train loss = 0.713332, test loss = 0.798526.\n",
      "Cluster 22: epoch = 00260, train loss = 0.705522, test loss = 0.793376.\n",
      "Cluster 22: epoch = 00270, train loss = 0.697791, test loss = 0.788307.\n",
      "Cluster 22: epoch = 00280, train loss = 0.690131, test loss = 0.783307.\n",
      "Cluster 22: epoch = 00290, train loss = 0.682537, test loss = 0.778371.\n",
      "Cluster 22: epoch = 00300, train loss = 0.675008, test loss = 0.773494.\n",
      "Cluster 22: epoch = 00310, train loss = 0.667544, test loss = 0.768677.\n",
      "Cluster 22: epoch = 00320, train loss = 0.660147, test loss = 0.763920.\n",
      "Cluster 22: epoch = 00330, train loss = 0.652819, test loss = 0.759224.\n",
      "Cluster 22: epoch = 00340, train loss = 0.645563, test loss = 0.754587.\n",
      "Cluster 22: epoch = 00350, train loss = 0.638381, test loss = 0.750015.\n",
      "Cluster 22: epoch = 00360, train loss = 0.631274, test loss = 0.745506.\n",
      "Cluster 22: epoch = 00370, train loss = 0.624245, test loss = 0.741060.\n",
      "Cluster 22: epoch = 00380, train loss = 0.617294, test loss = 0.736682.\n",
      "Cluster 22: epoch = 00390, train loss = 0.610424, test loss = 0.732368.\n",
      "Cluster 22: epoch = 00400, train loss = 0.603635, test loss = 0.728120.\n",
      "Cluster 22: epoch = 00410, train loss = 0.596930, test loss = 0.723939.\n",
      "Cluster 22: epoch = 00420, train loss = 0.590307, test loss = 0.719823.\n",
      "Cluster 22: epoch = 00430, train loss = 0.583769, test loss = 0.715770.\n",
      "Cluster 22: epoch = 00440, train loss = 0.577313, test loss = 0.711785.\n",
      "Cluster 22: epoch = 00450, train loss = 0.570943, test loss = 0.707864.\n",
      "Cluster 22: epoch = 00460, train loss = 0.564657, test loss = 0.704007.\n",
      "Cluster 22: epoch = 00470, train loss = 0.558455, test loss = 0.700217.\n",
      "Cluster 22: epoch = 00480, train loss = 0.552336, test loss = 0.696490.\n",
      "Cluster 22: epoch = 00490, train loss = 0.546302, test loss = 0.692829.\n",
      "Cluster 22: epoch = 00500, train loss = 0.540350, test loss = 0.689230.\n",
      "Cluster 22: epoch = 00510, train loss = 0.534481, test loss = 0.685695.\n",
      "Cluster 22: epoch = 00520, train loss = 0.528694, test loss = 0.682221.\n",
      "Cluster 22: epoch = 00530, train loss = 0.522989, test loss = 0.678808.\n",
      "Cluster 22: epoch = 00540, train loss = 0.517365, test loss = 0.675454.\n",
      "Cluster 22: epoch = 00550, train loss = 0.511819, test loss = 0.672159.\n",
      "Cluster 22: epoch = 00560, train loss = 0.506353, test loss = 0.668918.\n",
      "Cluster 22: epoch = 00570, train loss = 0.500965, test loss = 0.665734.\n",
      "Cluster 22: epoch = 00580, train loss = 0.495654, test loss = 0.662610.\n",
      "Cluster 22: epoch = 00590, train loss = 0.490420, test loss = 0.659542.\n",
      "Cluster 22: epoch = 00600, train loss = 0.485260, test loss = 0.656523.\n",
      "Cluster 22: epoch = 00610, train loss = 0.480174, test loss = 0.653553.\n",
      "Cluster 22: epoch = 00620, train loss = 0.475161, test loss = 0.650634.\n",
      "Cluster 22: epoch = 00630, train loss = 0.470221, test loss = 0.647764.\n",
      "Cluster 22: epoch = 00640, train loss = 0.465352, test loss = 0.644944.\n",
      "Cluster 22: epoch = 00650, train loss = 0.460553, test loss = 0.642175.\n",
      "Cluster 22: epoch = 00660, train loss = 0.455822, test loss = 0.639451.\n",
      "Cluster 22: epoch = 00670, train loss = 0.451159, test loss = 0.636774.\n",
      "Cluster 22: epoch = 00680, train loss = 0.446563, test loss = 0.634143.\n",
      "Cluster 22: epoch = 00690, train loss = 0.442032, test loss = 0.631556.\n",
      "Cluster 22: epoch = 00700, train loss = 0.437566, test loss = 0.629013.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 22 done in 0:00:01.789027.\n",
      "Writing the output model to \"./regularized_synonym_phi.k22.trained\".\n",
      "./regularized_synonym_phi.k23.trained\n",
      "Cluster 23: 152 train items and 38 test items available; using 1 steps of 152 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cluster 23: epoch = 00001, train loss = 1.950472, test loss = 1.946433.\n",
      "Cluster 23: epoch = 00010, train loss = 1.872033, test loss = 1.870900.\n",
      "Cluster 23: epoch = 00020, train loss = 1.746667, test loss = 1.750219.\n",
      "Cluster 23: epoch = 00030, train loss = 1.609264, test loss = 1.617985.\n",
      "Cluster 23: epoch = 00040, train loss = 1.474376, test loss = 1.488213.\n",
      "Cluster 23: epoch = 00050, train loss = 1.350287, test loss = 1.368900.\n",
      "Cluster 23: epoch = 00060, train loss = 1.241194, test loss = 1.264110.\n",
      "Cluster 23: epoch = 00070, train loss = 1.148498, test loss = 1.175215.\n",
      "Cluster 23: epoch = 00080, train loss = 1.071760, test loss = 1.101815.\n",
      "Cluster 23: epoch = 00090, train loss = 1.009470, test loss = 1.042473.\n",
      "Cluster 23: epoch = 00100, train loss = 0.959587, test loss = 0.995238.\n",
      "Cluster 23: epoch = 00110, train loss = 0.919921, test loss = 0.958008.\n",
      "Cluster 23: epoch = 00120, train loss = 0.888383, test loss = 0.928771.\n",
      "Cluster 23: epoch = 00130, train loss = 0.863108, test loss = 0.905729.\n",
      "Cluster 23: epoch = 00140, train loss = 0.842532, test loss = 0.887367.\n",
      "Cluster 23: epoch = 00150, train loss = 0.825395, test loss = 0.872459.\n",
      "Cluster 23: epoch = 00160, train loss = 0.810718, test loss = 0.860051.\n",
      "Cluster 23: epoch = 00170, train loss = 0.797769, test loss = 0.849422.\n",
      "Cluster 23: epoch = 00180, train loss = 0.786010, test loss = 0.840041.\n",
      "Cluster 23: epoch = 00190, train loss = 0.775063, test loss = 0.831528.\n",
      "Cluster 23: epoch = 00200, train loss = 0.764666, test loss = 0.823617.\n",
      "Cluster 23: epoch = 00210, train loss = 0.754643, test loss = 0.816128.\n",
      "Cluster 23: epoch = 00220, train loss = 0.744880, test loss = 0.808940.\n",
      "Cluster 23: epoch = 00230, train loss = 0.735304, test loss = 0.801970.\n",
      "Cluster 23: epoch = 00240, train loss = 0.725872, test loss = 0.795167.\n",
      "Cluster 23: epoch = 00250, train loss = 0.716558, test loss = 0.788501.\n",
      "Cluster 23: epoch = 00260, train loss = 0.707349, test loss = 0.781952.\n",
      "Cluster 23: epoch = 00270, train loss = 0.698240, test loss = 0.775509.\n",
      "Cluster 23: epoch = 00280, train loss = 0.689228, test loss = 0.769166.\n",
      "Cluster 23: epoch = 00290, train loss = 0.680315, test loss = 0.762919.\n",
      "Cluster 23: epoch = 00300, train loss = 0.671503, test loss = 0.756768.\n",
      "Cluster 23: epoch = 00310, train loss = 0.662796, test loss = 0.750712.\n",
      "Cluster 23: epoch = 00320, train loss = 0.654195, test loss = 0.744748.\n",
      "Cluster 23: epoch = 00330, train loss = 0.645704, test loss = 0.738880.\n",
      "Cluster 23: epoch = 00340, train loss = 0.637325, test loss = 0.733108.\n",
      "Cluster 23: epoch = 00350, train loss = 0.629060, test loss = 0.727432.\n",
      "Cluster 23: epoch = 00360, train loss = 0.620911, test loss = 0.721853.\n",
      "Cluster 23: epoch = 00370, train loss = 0.612879, test loss = 0.716371.\n",
      "Cluster 23: epoch = 00380, train loss = 0.604965, test loss = 0.710986.\n",
      "Cluster 23: epoch = 00390, train loss = 0.597170, test loss = 0.705696.\n",
      "Cluster 23: epoch = 00400, train loss = 0.589496, test loss = 0.700504.\n",
      "Cluster 23: epoch = 00410, train loss = 0.581940, test loss = 0.695407.\n",
      "Cluster 23: epoch = 00420, train loss = 0.574503, test loss = 0.690405.\n",
      "Cluster 23: epoch = 00430, train loss = 0.567186, test loss = 0.685498.\n",
      "Cluster 23: epoch = 00440, train loss = 0.559987, test loss = 0.680687.\n",
      "Cluster 23: epoch = 00450, train loss = 0.552907, test loss = 0.675967.\n",
      "Cluster 23: epoch = 00460, train loss = 0.545943, test loss = 0.671338.\n",
      "Cluster 23: epoch = 00470, train loss = 0.539095, test loss = 0.666794.\n",
      "Cluster 23: epoch = 00480, train loss = 0.532362, test loss = 0.662342.\n",
      "Cluster 23: epoch = 00490, train loss = 0.525741, test loss = 0.657977.\n",
      "Cluster 23: epoch = 00500, train loss = 0.519234, test loss = 0.653696.\n",
      "Cluster 23: epoch = 00510, train loss = 0.512836, test loss = 0.649499.\n",
      "Cluster 23: epoch = 00520, train loss = 0.506548, test loss = 0.645383.\n",
      "Cluster 23: epoch = 00530, train loss = 0.500368, test loss = 0.641349.\n",
      "Cluster 23: epoch = 00540, train loss = 0.494293, test loss = 0.637397.\n",
      "Cluster 23: epoch = 00550, train loss = 0.488323, test loss = 0.633524.\n",
      "Cluster 23: epoch = 00560, train loss = 0.482455, test loss = 0.629728.\n",
      "Cluster 23: epoch = 00570, train loss = 0.476688, test loss = 0.626003.\n",
      "Cluster 23: epoch = 00580, train loss = 0.471020, test loss = 0.622352.\n",
      "Cluster 23: epoch = 00590, train loss = 0.465450, test loss = 0.618775.\n",
      "Cluster 23: epoch = 00600, train loss = 0.459975, test loss = 0.615266.\n",
      "Cluster 23: epoch = 00610, train loss = 0.454594, test loss = 0.611825.\n",
      "Cluster 23: epoch = 00620, train loss = 0.449305, test loss = 0.608449.\n",
      "Cluster 23: epoch = 00630, train loss = 0.444106, test loss = 0.605136.\n",
      "Cluster 23: epoch = 00640, train loss = 0.438996, test loss = 0.601888.\n",
      "Cluster 23: epoch = 00650, train loss = 0.433973, test loss = 0.598700.\n",
      "Cluster 23: epoch = 00660, train loss = 0.429035, test loss = 0.595575.\n",
      "Cluster 23: epoch = 00670, train loss = 0.424180, test loss = 0.592508.\n",
      "Cluster 23: epoch = 00680, train loss = 0.419407, test loss = 0.589500.\n",
      "Cluster 23: epoch = 00690, train loss = 0.414714, test loss = 0.586547.\n",
      "Cluster 23: epoch = 00700, train loss = 0.410100, test loss = 0.583649.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 23 done in 0:00:01.915170.\n",
      "Writing the output model to \"./regularized_synonym_phi.k23.trained\".\n",
      "./regularized_synonym_phi.k24.trained\n",
      "Cluster 24: 166 train items and 48 test items available; using 1 steps of 166 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cluster 24: epoch = 00001, train loss = 1.946589, test loss = 1.940476.\n",
      "Cluster 24: epoch = 00010, train loss = 1.864942, test loss = 1.862423.\n",
      "Cluster 24: epoch = 00020, train loss = 1.735578, test loss = 1.738824.\n",
      "Cluster 24: epoch = 00030, train loss = 1.595357, test loss = 1.604890.\n",
      "Cluster 24: epoch = 00040, train loss = 1.459518, test loss = 1.475167.\n",
      "Cluster 24: epoch = 00050, train loss = 1.336435, test loss = 1.357674.\n",
      "Cluster 24: epoch = 00060, train loss = 1.230015, test loss = 1.256171.\n",
      "Cluster 24: epoch = 00070, train loss = 1.141164, test loss = 1.171560.\n",
      "Cluster 24: epoch = 00080, train loss = 1.068904, test loss = 1.102941.\n",
      "Cluster 24: epoch = 00090, train loss = 1.011225, test loss = 1.048423.\n",
      "Cluster 24: epoch = 00100, train loss = 0.965691, test loss = 1.005704.\n",
      "Cluster 24: epoch = 00110, train loss = 0.929847, test loss = 0.972450.\n",
      "Cluster 24: epoch = 00120, train loss = 0.901453, test loss = 0.946526.\n",
      "Cluster 24: epoch = 00130, train loss = 0.878603, test loss = 0.926109.\n",
      "Cluster 24: epoch = 00140, train loss = 0.859762, test loss = 0.909720.\n",
      "Cluster 24: epoch = 00150, train loss = 0.843746, test loss = 0.896211.\n",
      "Cluster 24: epoch = 00160, train loss = 0.829675, test loss = 0.884719.\n",
      "Cluster 24: epoch = 00170, train loss = 0.816917, test loss = 0.874625.\n",
      "Cluster 24: epoch = 00180, train loss = 0.805037, test loss = 0.865486.\n",
      "Cluster 24: epoch = 00190, train loss = 0.793737, test loss = 0.857000.\n",
      "Cluster 24: epoch = 00200, train loss = 0.782829, test loss = 0.848971.\n",
      "Cluster 24: epoch = 00210, train loss = 0.772192, test loss = 0.841265.\n",
      "Cluster 24: epoch = 00220, train loss = 0.761752, test loss = 0.833796.\n",
      "Cluster 24: epoch = 00230, train loss = 0.751469, test loss = 0.826516.\n",
      "Cluster 24: epoch = 00240, train loss = 0.741319, test loss = 0.819390.\n",
      "Cluster 24: epoch = 00250, train loss = 0.731293, test loss = 0.812397.\n",
      "Cluster 24: epoch = 00260, train loss = 0.721387, test loss = 0.805526.\n",
      "Cluster 24: epoch = 00270, train loss = 0.711601, test loss = 0.798773.\n",
      "Cluster 24: epoch = 00280, train loss = 0.701939, test loss = 0.792132.\n",
      "Cluster 24: epoch = 00290, train loss = 0.692403, test loss = 0.785600.\n",
      "Cluster 24: epoch = 00300, train loss = 0.682998, test loss = 0.779180.\n",
      "Cluster 24: epoch = 00310, train loss = 0.673725, test loss = 0.772873.\n",
      "Cluster 24: epoch = 00320, train loss = 0.664588, test loss = 0.766675.\n",
      "Cluster 24: epoch = 00330, train loss = 0.655590, test loss = 0.760590.\n",
      "Cluster 24: epoch = 00340, train loss = 0.646731, test loss = 0.754610.\n",
      "Cluster 24: epoch = 00350, train loss = 0.638013, test loss = 0.748742.\n",
      "Cluster 24: epoch = 00360, train loss = 0.629436, test loss = 0.742986.\n",
      "Cluster 24: epoch = 00370, train loss = 0.621000, test loss = 0.737341.\n",
      "Cluster 24: epoch = 00380, train loss = 0.612708, test loss = 0.731805.\n",
      "Cluster 24: epoch = 00390, train loss = 0.604557, test loss = 0.726378.\n",
      "Cluster 24: epoch = 00400, train loss = 0.596549, test loss = 0.721059.\n",
      "Cluster 24: epoch = 00410, train loss = 0.588680, test loss = 0.715842.\n",
      "Cluster 24: epoch = 00420, train loss = 0.580951, test loss = 0.710726.\n",
      "Cluster 24: epoch = 00430, train loss = 0.573360, test loss = 0.705712.\n",
      "Cluster 24: epoch = 00440, train loss = 0.565906, test loss = 0.700801.\n",
      "Cluster 24: epoch = 00450, train loss = 0.558586, test loss = 0.695990.\n",
      "Cluster 24: epoch = 00460, train loss = 0.551399, test loss = 0.691273.\n",
      "Cluster 24: epoch = 00470, train loss = 0.544344, test loss = 0.686653.\n",
      "Cluster 24: epoch = 00480, train loss = 0.537418, test loss = 0.682126.\n",
      "Cluster 24: epoch = 00490, train loss = 0.530618, test loss = 0.677691.\n",
      "Cluster 24: epoch = 00500, train loss = 0.523944, test loss = 0.673345.\n",
      "Cluster 24: epoch = 00510, train loss = 0.517392, test loss = 0.669082.\n",
      "Cluster 24: epoch = 00520, train loss = 0.510962, test loss = 0.664905.\n",
      "Cluster 24: epoch = 00530, train loss = 0.504648, test loss = 0.660812.\n",
      "Cluster 24: epoch = 00540, train loss = 0.498452, test loss = 0.656800.\n",
      "Cluster 24: epoch = 00550, train loss = 0.492369, test loss = 0.652865.\n",
      "Cluster 24: epoch = 00560, train loss = 0.486398, test loss = 0.649008.\n",
      "Cluster 24: epoch = 00570, train loss = 0.480536, test loss = 0.645225.\n",
      "Cluster 24: epoch = 00580, train loss = 0.474781, test loss = 0.641513.\n",
      "Cluster 24: epoch = 00590, train loss = 0.469130, test loss = 0.637875.\n",
      "Cluster 24: epoch = 00600, train loss = 0.463582, test loss = 0.634310.\n",
      "Cluster 24: epoch = 00610, train loss = 0.458135, test loss = 0.630809.\n",
      "Cluster 24: epoch = 00620, train loss = 0.452785, test loss = 0.627371.\n",
      "Cluster 24: epoch = 00630, train loss = 0.447531, test loss = 0.623999.\n",
      "Cluster 24: epoch = 00640, train loss = 0.442370, test loss = 0.620692.\n",
      "Cluster 24: epoch = 00650, train loss = 0.437303, test loss = 0.617442.\n",
      "Cluster 24: epoch = 00660, train loss = 0.432324, test loss = 0.614252.\n",
      "Cluster 24: epoch = 00670, train loss = 0.427433, test loss = 0.611125.\n",
      "Cluster 24: epoch = 00680, train loss = 0.422628, test loss = 0.608054.\n",
      "Cluster 24: epoch = 00690, train loss = 0.417908, test loss = 0.605036.\n",
      "Cluster 24: epoch = 00700, train loss = 0.413269, test loss = 0.602072.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 24 done in 0:00:02.011507.\n",
      "Writing the output model to \"./regularized_synonym_phi.k24.trained\".\n",
      "./regularized_synonym_phi.k25.trained\n",
      "Cluster 25: 72 train items and 20 test items available; using 1 steps of 72 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cluster 25: epoch = 00001, train loss = 1.856574, test loss = 1.797412.\n",
      "Cluster 25: epoch = 00010, train loss = 1.826141, test loss = 1.767758.\n",
      "Cluster 25: epoch = 00020, train loss = 1.774046, test loss = 1.717089.\n",
      "Cluster 25: epoch = 00030, train loss = 1.711911, test loss = 1.656826.\n",
      "Cluster 25: epoch = 00040, train loss = 1.644542, test loss = 1.591725.\n",
      "Cluster 25: epoch = 00050, train loss = 1.575135, test loss = 1.524952.\n",
      "Cluster 25: epoch = 00060, train loss = 1.505959, test loss = 1.458757.\n",
      "Cluster 25: epoch = 00070, train loss = 1.438626, test loss = 1.394725.\n",
      "Cluster 25: epoch = 00080, train loss = 1.374259, test loss = 1.333957.\n",
      "Cluster 25: epoch = 00090, train loss = 1.313590, test loss = 1.277156.\n",
      "Cluster 25: epoch = 00100, train loss = 1.257076, test loss = 1.224753.\n",
      "Cluster 25: epoch = 00110, train loss = 1.204928, test loss = 1.176924.\n",
      "Cluster 25: epoch = 00120, train loss = 1.157187, test loss = 1.133681.\n",
      "Cluster 25: epoch = 00130, train loss = 1.113757, test loss = 1.094895.\n",
      "Cluster 25: epoch = 00140, train loss = 1.074446, test loss = 1.060348.\n",
      "Cluster 25: epoch = 00150, train loss = 1.038999, test loss = 1.029754.\n",
      "Cluster 25: epoch = 00160, train loss = 1.007120, test loss = 1.002794.\n",
      "Cluster 25: epoch = 00170, train loss = 0.978490, test loss = 0.979121.\n",
      "Cluster 25: epoch = 00180, train loss = 0.952779, test loss = 0.958385.\n",
      "Cluster 25: epoch = 00190, train loss = 0.929667, test loss = 0.940244.\n",
      "Cluster 25: epoch = 00200, train loss = 0.908849, test loss = 0.924382.\n",
      "Cluster 25: epoch = 00210, train loss = 0.890024, test loss = 0.910480.\n",
      "Cluster 25: epoch = 00220, train loss = 0.872931, test loss = 0.898267.\n",
      "Cluster 25: epoch = 00230, train loss = 0.857329, test loss = 0.887494.\n",
      "Cluster 25: epoch = 00240, train loss = 0.842999, test loss = 0.877933.\n",
      "Cluster 25: epoch = 00250, train loss = 0.829750, test loss = 0.869389.\n",
      "Cluster 25: epoch = 00260, train loss = 0.817411, test loss = 0.861692.\n",
      "Cluster 25: epoch = 00270, train loss = 0.805838, test loss = 0.854693.\n",
      "Cluster 25: epoch = 00280, train loss = 0.794909, test loss = 0.848263.\n",
      "Cluster 25: epoch = 00290, train loss = 0.784516, test loss = 0.842299.\n",
      "Cluster 25: epoch = 00300, train loss = 0.774572, test loss = 0.836710.\n",
      "Cluster 25: epoch = 00310, train loss = 0.765004, test loss = 0.831426.\n",
      "Cluster 25: epoch = 00320, train loss = 0.755751, test loss = 0.826393.\n",
      "Cluster 25: epoch = 00330, train loss = 0.746763, test loss = 0.821561.\n",
      "Cluster 25: epoch = 00340, train loss = 0.737996, test loss = 0.816887.\n",
      "Cluster 25: epoch = 00350, train loss = 0.729421, test loss = 0.812342.\n",
      "Cluster 25: epoch = 00360, train loss = 0.721010, test loss = 0.807906.\n",
      "Cluster 25: epoch = 00370, train loss = 0.712743, test loss = 0.803560.\n",
      "Cluster 25: epoch = 00380, train loss = 0.704607, test loss = 0.799289.\n",
      "Cluster 25: epoch = 00390, train loss = 0.696586, test loss = 0.795085.\n",
      "Cluster 25: epoch = 00400, train loss = 0.688671, test loss = 0.790937.\n",
      "Cluster 25: epoch = 00410, train loss = 0.680853, test loss = 0.786843.\n",
      "Cluster 25: epoch = 00420, train loss = 0.673130, test loss = 0.782798.\n",
      "Cluster 25: epoch = 00430, train loss = 0.665495, test loss = 0.778797.\n",
      "Cluster 25: epoch = 00440, train loss = 0.657947, test loss = 0.774847.\n",
      "Cluster 25: epoch = 00450, train loss = 0.650482, test loss = 0.770941.\n",
      "Cluster 25: epoch = 00460, train loss = 0.643101, test loss = 0.767082.\n",
      "Cluster 25: epoch = 00470, train loss = 0.635801, test loss = 0.763264.\n",
      "Cluster 25: epoch = 00480, train loss = 0.628582, test loss = 0.759492.\n",
      "Cluster 25: epoch = 00490, train loss = 0.621443, test loss = 0.755765.\n",
      "Cluster 25: epoch = 00500, train loss = 0.614386, test loss = 0.752086.\n",
      "Cluster 25: epoch = 00510, train loss = 0.607410, test loss = 0.748452.\n",
      "Cluster 25: epoch = 00520, train loss = 0.600514, test loss = 0.744868.\n",
      "Cluster 25: epoch = 00530, train loss = 0.593699, test loss = 0.741335.\n",
      "Cluster 25: epoch = 00540, train loss = 0.586965, test loss = 0.737855.\n",
      "Cluster 25: epoch = 00550, train loss = 0.580310, test loss = 0.734419.\n",
      "Cluster 25: epoch = 00560, train loss = 0.573737, test loss = 0.731032.\n",
      "Cluster 25: epoch = 00570, train loss = 0.567244, test loss = 0.727698.\n",
      "Cluster 25: epoch = 00580, train loss = 0.560830, test loss = 0.724412.\n",
      "Cluster 25: epoch = 00590, train loss = 0.554496, test loss = 0.721175.\n",
      "Cluster 25: epoch = 00600, train loss = 0.548241, test loss = 0.717985.\n",
      "Cluster 25: epoch = 00610, train loss = 0.542066, test loss = 0.714843.\n",
      "Cluster 25: epoch = 00620, train loss = 0.535970, test loss = 0.711750.\n",
      "Cluster 25: epoch = 00630, train loss = 0.529954, test loss = 0.708704.\n",
      "Cluster 25: epoch = 00640, train loss = 0.524015, test loss = 0.705709.\n",
      "Cluster 25: epoch = 00650, train loss = 0.518154, test loss = 0.702765.\n",
      "Cluster 25: epoch = 00660, train loss = 0.512370, test loss = 0.699867.\n",
      "Cluster 25: epoch = 00670, train loss = 0.506663, test loss = 0.697016.\n",
      "Cluster 25: epoch = 00680, train loss = 0.501031, test loss = 0.694216.\n",
      "Cluster 25: epoch = 00690, train loss = 0.495475, test loss = 0.691466.\n",
      "Cluster 25: epoch = 00700, train loss = 0.489993, test loss = 0.688761.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 25 done in 0:00:01.556090.\n",
      "Writing the output model to \"./regularized_synonym_phi.k25.trained\".\n",
      "Writing the test data to \"regularized_synonym_phi.test.npz\".\n"
     ]
    }
   ],
   "source": [
    "model = MODELS[model_type](x_size=Z_all_train.shape[1], y_size=Y_all_train.shape[1], w_stddev=stddev, lambda_=lambdac)\n",
    "print(model, flush=True)\n",
    "\n",
    "for path in glob.glob('%s.k*.trained*' % model_type):\n",
    "    print('Removing a stale file: \"%s\".' % path, flush=True)\n",
    "    os.remove(path)\n",
    "\n",
    "if os.path.isfile('%s.test.npz' % model_type):\n",
    "    print('Removing a stale file: \"%s\".' % ('%s.test.npz' % model_type), flush=True)\n",
    "    os.remove('%s.test.npz' % model_type)\n",
    "\n",
    "Y_hat_test = {}\n",
    "\n",
    "for cluster in range(kmeans.n_clusters):\n",
    "    data = Data(\n",
    "        cluster, clusters_train, clusters_test,\n",
    "        X_index_train, Y_all_train, Z_all_train,\n",
    "        X_index_test,  Y_all_test,  Z_all_test\n",
    "    )\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    saver_path = './%s.k%d.trained' % (model_type, cluster + 1)\n",
    "    print (saver_path)\n",
    "    Y_hat_test[str(cluster)] = train(model, data, callback=lambda sess: saver.save(sess, saver_path))\n",
    "    print('Writing the output model to \"%s\".' % saver_path, flush=True)\n",
    "\n",
    "test_path = '%s.test.npz' % model_type\n",
    "np.savez_compressed(test_path, **Y_hat_test)\n",
    "print('Writing the test data to \"%s\".' % test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create directory ./ft-300-k25-l0.1/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./ft-300-k25-l0.1/kmeans.pickle'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move generated checkpoint files, \n",
    "if not w2v:\n",
    "    directory = './ft-300-k%02d-l%.1f/' % (cluster+1, lambdac)\n",
    "else:\n",
    "    directory = './en_300-k%02d-l%.1f/' % (cluster+1, lambdac)\n",
    "\n",
    "# create directory if it doesn't exist already\n",
    "if not os.path.exists(directory):\n",
    "    print (\"Create directory %s\" % (directory))\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# move all interim checkpoints and final model to designated directory\n",
    "output_files = glob.glob('%s.*.trained*'%(model_type))\n",
    "if os.path.exists('%s.test.npz'%(model_type)):\n",
    "    output_files.append('%s.test.npz'%(model_type))\n",
    "\n",
    "for file in output_files:\n",
    "    os.rename(\"./%s\"%(file), \"%s%s\"%(directory, file))\n",
    "    \n",
    "# copy cluster pickle to directory as well\n",
    "shutil.copy2('./kmeans.pickle', directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
